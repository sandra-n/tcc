{"metadata":{"colab":{"provenance":[],"collapsed_sections":["orC9lkWEXoBL"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"e92cc3d26c38c253be3220a870a337609e115e6bcf47fea649f85669fc5c0a76"}},"gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Imports and packages"],"metadata":{"id":"Z_CnjGOo8R1p"}},{"cell_type":"code","source":["!pip install emoji==1.7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcVNUpa1WPTL","outputId":"f3972cb5-4e40-4f9d-8b7f-76e8377c29e5","execution":{"iopub.status.busy":"2022-11-26T22:47:21.004027Z","iopub.execute_input":"2022-11-26T22:47:21.005033Z","iopub.status.idle":"2022-11-26T22:47:30.375959Z","shell.execute_reply.started":"2022-11-26T22:47:21.004943Z","shell.execute_reply":"2022-11-26T22:47:30.374841Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019299131,"user_tz":180,"elapsed":11792,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji==1.7\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 43.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 112 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 122 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 163 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 174 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 14.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=54f2279510a1698c05077fe28a37f414dca5b5b88b0360c0a67214ff68dc3249\n","  Stored in directory: /root/.cache/pip/wheels/5e/8c/80/c3646df8201ba6f5070297fe3779a4b70265d0bfd961c15302\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-1.7.0\n"]}]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6o3fjcWWTG4","outputId":"b8952eac-46af-4b46-d1bb-dc2b14bd6f2c","execution":{"iopub.status.busy":"2022-11-26T22:47:30.378894Z","iopub.execute_input":"2022-11-26T22:47:30.379957Z","iopub.status.idle":"2022-11-26T22:47:39.725993Z","shell.execute_reply.started":"2022-11-26T22:47:30.379915Z","shell.execute_reply":"2022-11-26T22:47:39.724858Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019304719,"user_tz":180,"elapsed":5592,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchinfo\n","  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.7.1\n"]}]},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDdnwEncWsTM","outputId":"9fc15047-b1c1-45b2-ed3d-840d3d012590","execution":{"iopub.status.busy":"2022-11-26T22:47:39.727518Z","iopub.execute_input":"2022-11-26T22:47:39.727832Z","iopub.status.idle":"2022-11-26T22:47:49.426365Z","shell.execute_reply.started":"2022-11-26T22:47:39.727793Z","shell.execute_reply":"2022-11-26T22:47:49.425176Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019308152,"user_tz":180,"elapsed":3436,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","from torchinfo import summary\n","\n","from emoji import UNICODE_EMOJI"],"metadata":{"id":"iTfnXbs0301B","execution":{"iopub.status.busy":"2022-11-26T22:47:49.429415Z","iopub.execute_input":"2022-11-26T22:47:49.429807Z","iopub.status.idle":"2022-11-26T22:47:50.169327Z","shell.execute_reply.started":"2022-11-26T22:47:49.429766Z","shell.execute_reply":"2022-11-26T22:47:50.168192Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019310887,"user_tz":180,"elapsed":2738,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('averaged_perceptron_tagger')\n","stopwords_set = set(stopwords.words('english'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYmvWKEXWzKI","outputId":"3afcfb3a-e887-44c9-b09b-cab55ab61985","execution":{"iopub.status.busy":"2022-11-26T22:47:50.174819Z","iopub.execute_input":"2022-11-26T22:47:50.177549Z","iopub.status.idle":"2022-11-26T22:47:51.068295Z","shell.execute_reply.started":"2022-11-26T22:47:50.177506Z","shell.execute_reply":"2022-11-26T22:47:51.067210Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019313021,"user_tz":180,"elapsed":2139,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43k8_QoJWgDQ","outputId":"3c2230cc-f5a5-4fa6-d64c-6698289cb66f","execution":{"iopub.status.busy":"2022-11-26T22:47:51.069860Z","iopub.execute_input":"2022-11-26T22:47:51.070523Z","iopub.status.idle":"2022-11-26T22:47:51.075875Z","shell.execute_reply.started":"2022-11-26T22:47:51.070466Z","shell.execute_reply":"2022-11-26T22:47:51.074690Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019335781,"user_tz":180,"elapsed":22763,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Base de treino - classificado"],"metadata":{"id":"yOHhfGNAaQ2V"}},{"cell_type":"code","source":["df_train = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset/big_train_dataset.feather')\n","df_val = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset/big_val_dataset.feather')\n","df_test = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset/big_test_dataset.feather')\n","\n","display(df_train)\n","display(df_val)\n","display(df_test)"],"metadata":{"id":"JvumcICn4PWp","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a819e0ba-d1d5-4d32-b3b1-06afe403dca8","execution":{"iopub.status.busy":"2022-11-26T22:47:51.077390Z","iopub.execute_input":"2022-11-26T22:47:51.078077Z","iopub.status.idle":"2022-11-26T22:47:52.407103Z","shell.execute_reply.started":"2022-11-26T22:47:51.078041Z","shell.execute_reply":"2022-11-26T22:47:52.406081Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019420695,"user_tz":180,"elapsed":4130,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["          index                                               text  label\n","0             0  @9s_Watch @FuckChina721831 @MOFA_Taiwan @WHO T...    0.0\n","1             1  IF THIS GOES ANY FURTHER, WITH CORONA VIRUS; T...    0.0\n","2             2  BBC News - Coronavirus : South Korean sect ide...    1.0\n","3             3  Unique ordeal': Wuhan evacuees head home after...    1.0\n","4             4  Salam, kmss ada group support tak for ladies? ...    1.0\n","...         ...                                                ...    ...\n","1167510  999333                                 chink boi wna walk    0.0\n","1167511  999334  what the fuckkkkkk ? ? ? ? ? ? . . . how can i...    0.0\n","1167512  999336                                       damn covid .    0.0\n","1167513  999340  hey jack ma . the entire world mess \"chinese v...    0.0\n","1167514  999344               covid killed fuck neil lennon done .    0.0\n","\n","[1167515 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b48653b1-9777-4fd9-ad02-bb80e09aa938\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>@9s_Watch @FuckChina721831 @MOFA_Taiwan @WHO T...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>IF THIS GOES ANY FURTHER, WITH CORONA VIRUS; T...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>BBC News - Coronavirus : South Korean sect ide...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Unique ordeal': Wuhan evacuees head home after...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Salam, kmss ada group support tak for ladies? ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1167510</th>\n","      <td>999333</td>\n","      <td>chink boi wna walk</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1167511</th>\n","      <td>999334</td>\n","      <td>what the fuckkkkkk ? ? ? ? ? ? . . . how can i...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1167512</th>\n","      <td>999336</td>\n","      <td>damn covid .</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1167513</th>\n","      <td>999340</td>\n","      <td>hey jack ma . the entire world mess \"chinese v...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1167514</th>\n","      <td>999344</td>\n","      <td>covid killed fuck neil lennon done .</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1167515 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b48653b1-9777-4fd9-ad02-bb80e09aa938')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b48653b1-9777-4fd9-ad02-bb80e09aa938 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b48653b1-9777-4fd9-ad02-bb80e09aa938');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["         index                                               text  label\n","0            0  @cfyneufx123 @kpru This mongoloid came to kill...    0.0\n","1            1  Holy shit, based ching chong alert. 🚨 https://...    0.0\n","2            2  The MSM gives you disinfectants that MAY kill ...    1.0\n","3            3                       No kiss, No hug #coronavirus    1.0\n","4            4  @parasocialanxi1 Don't feel bad if it's the na...    1.0\n","...        ...                                                ...    ...\n","145933   93887  chinese people recently kills baluchistan libe...    1.0\n","145934    7292  i suspects evans may 're get give monkey scrub...    1.0\n","145935  592046                                      exfuckingcuse    0.0\n","145936  774781  three college-age cousins covid . so that’s fu...    1.0\n","145937  862060  never forget covid-19 . china regime lied kill...    0.0\n","\n","[145938 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-ba3103b4-4c43-4478-a549-daf4f1a67ea6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>@cfyneufx123 @kpru This mongoloid came to kill...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Holy shit, based ching chong alert. 🚨 https://...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>The MSM gives you disinfectants that MAY kill ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>No kiss, No hug #coronavirus</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>@parasocialanxi1 Don't feel bad if it's the na...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145933</th>\n","      <td>93887</td>\n","      <td>chinese people recently kills baluchistan libe...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145934</th>\n","      <td>7292</td>\n","      <td>i suspects evans may 're get give monkey scrub...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145935</th>\n","      <td>592046</td>\n","      <td>exfuckingcuse</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>145936</th>\n","      <td>774781</td>\n","      <td>three college-age cousins covid . so that’s fu...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145937</th>\n","      <td>862060</td>\n","      <td>never forget covid-19 . china regime lied kill...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>145938 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba3103b4-4c43-4478-a549-daf4f1a67ea6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ba3103b4-4c43-4478-a549-daf4f1a67ea6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ba3103b4-4c43-4478-a549-daf4f1a67ea6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["         index                                               text  label\n","0            0  Coronavirus Election Puts the Democrats In a D...    0.0\n","1            1  🦠🦠☠️☠️ You are a poor ghost from: Kenya.  Nigg...    0.0\n","2            2  The President of the US calling COVID-19 the ‘...    0.0\n","3            3  @NortherntreeY @Lyndsayunihead @sarahgrowls @r...    0.0\n","4            4  At the very least,  China needs to be isolated...    0.0\n","...        ...                                                ...    ...\n","145935   17901  we because never levels. even japanese wagyu h...    1.0\n","145936  167333  asian problems : non-asian friends asks transl...    1.0\n","145937  747222  amazing learn work . a colleague told avoid an...    1.0\n","145938   36361  2021 global travel forecast : what impact will...    1.0\n","145939   60842  too fun straight guys finding i ‘ m korean say...    1.0\n","\n","[145940 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-6d581d1d-3f38-4df5-bc22-05cb19eaa8f3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Coronavirus Election Puts the Democrats In a D...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>🦠🦠☠️☠️ You are a poor ghost from: Kenya.  Nigg...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>The President of the US calling COVID-19 the ‘...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>@NortherntreeY @Lyndsayunihead @sarahgrowls @r...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>At the very least,  China needs to be isolated...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145935</th>\n","      <td>17901</td>\n","      <td>we because never levels. even japanese wagyu h...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145936</th>\n","      <td>167333</td>\n","      <td>asian problems : non-asian friends asks transl...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145937</th>\n","      <td>747222</td>\n","      <td>amazing learn work . a colleague told avoid an...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145938</th>\n","      <td>36361</td>\n","      <td>2021 global travel forecast : what impact will...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145939</th>\n","      <td>60842</td>\n","      <td>too fun straight guys finding i ‘ m korean say...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>145940 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d581d1d-3f38-4df5-bc22-05cb19eaa8f3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6d581d1d-3f38-4df5-bc22-05cb19eaa8f3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6d581d1d-3f38-4df5-bc22-05cb19eaa8f3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.utils import shuffle\n","display(df_val)\n","\n","df_train = shuffle(df_train)\n","df_val = shuffle(df_val)\n","df_test = shuffle(df_test)\n","\n","display(df_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":830},"id":"trnw9HybW7C8","outputId":"aba4b70c-d0e1-45fb-ce36-2dc0dca375ad","execution":{"iopub.status.busy":"2022-11-26T22:47:52.408591Z","iopub.execute_input":"2022-11-26T22:47:52.409284Z","iopub.status.idle":"2022-11-26T22:47:52.782596Z","shell.execute_reply.started":"2022-11-26T22:47:52.409243Z","shell.execute_reply":"2022-11-26T22:47:52.781693Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019421165,"user_tz":180,"elapsed":474,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["         index                                               text  label\n","0            0  @cfyneufx123 @kpru This mongoloid came to kill...    0.0\n","1            1  Holy shit, based ching chong alert. 🚨 https://...    0.0\n","2            2  The MSM gives you disinfectants that MAY kill ...    1.0\n","3            3                       No kiss, No hug #coronavirus    1.0\n","4            4  @parasocialanxi1 Don't feel bad if it's the na...    1.0\n","...        ...                                                ...    ...\n","145933   93887  chinese people recently kills baluchistan libe...    1.0\n","145934    7292  i suspects evans may 're get give monkey scrub...    1.0\n","145935  592046                                      exfuckingcuse    0.0\n","145936  774781  three college-age cousins covid . so that’s fu...    1.0\n","145937  862060  never forget covid-19 . china regime lied kill...    0.0\n","\n","[145938 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-c93ddd59-49a6-477e-9c71-569deebb0a49\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>@cfyneufx123 @kpru This mongoloid came to kill...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Holy shit, based ching chong alert. 🚨 https://...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>The MSM gives you disinfectants that MAY kill ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>No kiss, No hug #coronavirus</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>@parasocialanxi1 Don't feel bad if it's the na...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145933</th>\n","      <td>93887</td>\n","      <td>chinese people recently kills baluchistan libe...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145934</th>\n","      <td>7292</td>\n","      <td>i suspects evans may 're get give monkey scrub...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145935</th>\n","      <td>592046</td>\n","      <td>exfuckingcuse</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>145936</th>\n","      <td>774781</td>\n","      <td>three college-age cousins covid . so that’s fu...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>145937</th>\n","      <td>862060</td>\n","      <td>never forget covid-19 . china regime lied kill...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>145938 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c93ddd59-49a6-477e-9c71-569deebb0a49')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c93ddd59-49a6-477e-9c71-569deebb0a49 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c93ddd59-49a6-477e-9c71-569deebb0a49');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["         index                                               text  label\n","50417   792807  um , know mike hot press secretary swore f sto...    1.0\n","92256   471041  bloody #chinese ! we don’t need #india . #boyc...    0.0\n","98567   400946  who americans slaughtered chinese government ....    0.0\n","77466    88948  thats but manuva bit close hot southeast asian...    1.0\n","19874    42923  it ' s 'm really ' f much happier japanese car...    1.0\n","...        ...                                                ...    ...\n","141313   15777  cellist morgannwg decide # missbombay # jbas #...    1.0\n","55682   218803  while nigerian government attending cop26 even...    1.0\n","2187     60655  no several things video relatable lol! not im ...    1.0\n","23121   738374  cold thermal magnetic vampire membrane eddie-c...    0.0\n","144696  726177  #ccpchina #chinaliedandpeopledied #standwithho...    0.0\n","\n","[145938 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-645f4bd8-f5b9-426b-8c0a-80232855f1e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>50417</th>\n","      <td>792807</td>\n","      <td>um , know mike hot press secretary swore f sto...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>92256</th>\n","      <td>471041</td>\n","      <td>bloody #chinese ! we don’t need #india . #boyc...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>98567</th>\n","      <td>400946</td>\n","      <td>who americans slaughtered chinese government ....</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>77466</th>\n","      <td>88948</td>\n","      <td>thats but manuva bit close hot southeast asian...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>19874</th>\n","      <td>42923</td>\n","      <td>it ' s 'm really ' f much happier japanese car...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>141313</th>\n","      <td>15777</td>\n","      <td>cellist morgannwg decide # missbombay # jbas #...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>55682</th>\n","      <td>218803</td>\n","      <td>while nigerian government attending cop26 even...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2187</th>\n","      <td>60655</td>\n","      <td>no several things video relatable lol! not im ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>23121</th>\n","      <td>738374</td>\n","      <td>cold thermal magnetic vampire membrane eddie-c...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>144696</th>\n","      <td>726177</td>\n","      <td>#ccpchina #chinaliedandpeopledied #standwithho...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>145938 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-645f4bd8-f5b9-426b-8c0a-80232855f1e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-645f4bd8-f5b9-426b-8c0a-80232855f1e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-645f4bd8-f5b9-426b-8c0a-80232855f1e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["train_y = df_train['label']\n","train_x = df_train['text']\n","\n","val_y = df_val['label']\n","val_x = df_val['text']\n","\n","test_y = df_test['label']\n","test_x = df_test['text']"],"metadata":{"id":"6nlrv-fDTluW","execution":{"iopub.status.busy":"2022-11-26T22:47:52.783893Z","iopub.execute_input":"2022-11-26T22:47:52.784268Z","iopub.status.idle":"2022-11-26T22:47:52.792963Z","shell.execute_reply.started":"2022-11-26T22:47:52.784233Z","shell.execute_reply":"2022-11-26T22:47:52.790622Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019421166,"user_tz":180,"elapsed":3,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Dataprep"],"metadata":{"id":"OXGZ5w4mA1p8"}},{"cell_type":"code","source":["stopwords_set.add('\\u200d')\n","stopwords_set.add(' ')"],"metadata":{"execution":{"iopub.status.busy":"2022-11-26T22:47:52.796962Z","iopub.execute_input":"2022-11-26T22:47:52.797252Z","iopub.status.idle":"2022-11-26T22:47:52.802886Z","shell.execute_reply.started":"2022-11-26T22:47:52.797227Z","shell.execute_reply":"2022-11-26T22:47:52.801187Z"},"trusted":true,"id":"mD-iUKnp5nsH","executionInfo":{"status":"ok","timestamp":1670019423541,"user_tz":180,"elapsed":1,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def removeMention(tweet):\n","    words = tweet.split()\n","    words = [word for word in words if \"@\" not in word ]\n","    newTweet = ' '.join(words)\n","    return newTweet\n","\n","  # substituir menção por <USER>\n","\n","# search your emoji\n","def is_emoji(s, language=\"en\"):\n","    return s in UNICODE_EMOJI[language]\n","\n","# add space near your emoji\n","def add_space(text):\n","    return ''.join(' ' + char + ' ' if is_emoji(char) else char for char in text).strip()\n","\n","def separateEmoji(tweet):\n","    return add_space(tweet)\n","\n","import re\n","regex = re.compile(\"(http://t\\.co.{12})|(https://t\\.co.{11})\")\n","\n","def removeLink(tweet):\n","    #words = tweet.split()\n","    #links = [word for word in words if \"t.co\" in word]\n","    words = regex.sub('',tweet)\n","    return words\n","\n","def splitPunctuation(tweet):\n","    tweet = tweet.replace(\".\", \" . \").replace(\",\", \" , \").replace(\";\", \" ; \")\\\n","        .replace(\"!\", \" ! \").replace(\"?\", \" ? \").replace(\":\", \" : \")\\\n","        .replace(\"(\", \" ( \").replace(\")\", \" ) \")\n","    return tweet\n","\n","def remove_stopwords(tweet):\n","    words = tweet.split()\n","    words = [word for word in words if not word in stopwords_set]\n","    newTweet = ' '.join(words)\n","    return newTweet\n","\n","def lower_tweet(tweet):\n","    return tweet.lower()"],"metadata":{"id":"Q2eQCuMl4tIn","execution":{"iopub.status.busy":"2022-11-26T22:47:52.805130Z","iopub.execute_input":"2022-11-26T22:47:52.805555Z","iopub.status.idle":"2022-11-26T22:47:52.817481Z","shell.execute_reply.started":"2022-11-26T22:47:52.805521Z","shell.execute_reply":"2022-11-26T22:47:52.816426Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019424272,"user_tz":180,"elapsed":3,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_x = train_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","val_x = val_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","test_x = test_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","\n","train_x.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gX3FHsOG4x5q","outputId":"a29d4583-0b8d-43d2-c2f4-8d7f276bfa8a","execution":{"iopub.status.busy":"2022-11-26T22:47:52.819617Z","iopub.execute_input":"2022-11-26T22:47:52.819881Z","iopub.status.idle":"2022-11-26T22:49:00.677972Z","shell.execute_reply.started":"2022-11-26T22:47:52.819857Z","shell.execute_reply":"2022-11-26T22:49:00.677016Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019475273,"user_tz":180,"elapsed":49981,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["169567    britain's independent bookshops rallying help ...\n","570303    161&lt ; vote bad buddy best asian series sec ...\n","490499    european cabinet last 1997 approving opening c...\n","621302    year hate extremism 2020 : organized hate grou...\n","62559     . also respect people asian ethnicities . inte...\n","Name: text, dtype: object"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# display(train_y.head())\n","# display(train_y.value_counts())\n","\n","# train_y = train_y.mask(train_y==0, 1)\n","# train_y = train_y.mask(train_y==2, 0)\n","\n","# val_y = val_y.mask(val_y==0, 1)\n","# val_y = val_y.mask(val_y==2, 0)\n","\n","# test_y = test_y.mask(test_y==0, 1)\n","# test_y = test_y.mask(test_y==2, 0)\n","\n","# display(train_y.head())\n","display(train_y.value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"Sed8Sz8fXeUT","outputId":"7c1f4e82-b8cb-45c7-90f7-2305a1455c0f","execution":{"iopub.status.busy":"2022-11-26T22:49:00.679562Z","iopub.execute_input":"2022-11-26T22:49:00.680276Z","iopub.status.idle":"2022-11-26T22:49:00.706366Z","shell.execute_reply.started":"2022-11-26T22:49:00.680239Z","shell.execute_reply":"2022-11-26T22:49:00.705144Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670019528108,"user_tz":180,"elapsed":302,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["1.0    778520\n","0.0    388995\n","Name: label, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":["from collections import Counter\n","\n","\n","def tweets_vocab(dataset, n=None):\n","    if n is None:\n","        n = len(dataset)\n","    all_tweets = []\n","    for tweet in dataset:\n","        words = tweet.split()\n","        all_tweets.append(words)\n","\n","    all_tweets = [item for sublist in all_tweets for item in sublist]\n","    #print(all_tweets)\n","    counter_words = Counter(all_tweets)\n","    #print(counter_words)\n","    #print(len(counter_words))\n","    counter_words = counter_words.most_common(n)\n","    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(counter_words)}\n","    #print(vocab_to_int)\n","    return vocab_to_int\n","  \n","def padding(dataset_tok, max_len):\n","    for i in range(len(dataset_tok)):\n","        if len(dataset_tok[i]) < max_len:\n","          #if len(dataset_tok[i]) < max_len:\n","          for z in range(max_len - len(dataset_tok[i])):\n","          #for z in range(max_len - len(tweet)):\n","              # dataset_tok[i].append([0])\n","              dataset_tok[i] = [[0]] + dataset_tok[i]\n","              #tweet.append(0)\n","    return np.array(dataset_tok)\n","\n","def tweets_tok(dataset, vocab_to_int):\n","\n","    dataset_tok = []\n","    max_len = 0\n","\n","    # for tweet in dataset_tok:\n","    #   print(tweet)\n","    #     r = [vocab_to_int[w] if w in vocab_to_int else 0 for w in tweet.split()]\n","    #     dataset_tok[tweet]=r\n","    #     #print(r)\n","    #     #tweet = r\n","    for i in range(len(dataset)):\n","        r = [[vocab_to_int[w]] for w in dataset.iloc[i].split() if w in vocab_to_int]\n","        dataset_tok.append(r)\n","        #dataset_tok.iloc[i] = r\n","\n","        if len(r) > max_len:\n","            max_len = len(r)\n","            tweet = r\n","            ind = i\n","    print(tweet, ind, len(tweet), dataset[ind])\n","    # # padding\n","    # for i in range(len(dataset_tok)):\n","    #     #if len(dataset_tok.iloc[i]) < max_len:\n","    #     if len(dataset_tok[i]) < max_len:\n","    #         #for z in range(max_len - len(dataset_tok.iloc[i])):\n","    #         for z in range(max_len - len(dataset_tok[i])):\n","    #             #dataset_tok.iloc[i].append(0)\n","    #             dataset_tok[i].append(0)\n","\n","    return dataset_tok, max_len"],"metadata":{"id":"L5bACEEIXhSn","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670019600716,"user_tz":180,"elapsed":69048,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}},"outputId":"ced18d03-7b99-4a7c-ede8-6fb1d4ccea5a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["392766\n"]}]},{"cell_type":"code","source":["vocab_to_int = tweets_vocab(train_x)\n","train_x_tok, max_len1 = tweets_tok(train_x, vocab_to_int)\n","test_x_tok, _ = tweets_tok(test_x, vocab_to_int)\n","val_x_tok, _ = tweets_tok(val_x, vocab_to_int)\n"],"metadata":{"id":"FT1RcsZO60IL","executionInfo":{"status":"ok","timestamp":1670019652534,"user_tz":180,"elapsed":783,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["max_len = 280\n","val_x_tok = padding(val_x_tok, max_len)\n","test_x_tok = padding(test_x_tok, max_len)"],"metadata":{"id":"ubcFGjND6z8z","executionInfo":{"status":"ok","timestamp":1670019660720,"user_tz":180,"elapsed":6040,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["train_x_padded = np.array(train_x_padded)\n","val_x_padded = np.array(val_x_padded)\n","test_x_padded = np.array(test_x_padded)\n","\n","train_y = np.array(train_y)\n","val_y = np.array(val_y)\n","test_y = np.array(test_y)"],"metadata":{"id":"7GG3Vfhx7Bzs","executionInfo":{"status":"ok","timestamp":1670019660721,"user_tz":180,"elapsed":12,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# LSTM"],"metadata":{"id":"orC9lkWEXoBL"}},{"cell_type":"markdown","source":["# Bag of words"],"metadata":{"id":"zheMpxKPU0qm"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"id":"jEmyuK61cggn","execution":{"iopub.status.busy":"2022-11-26T23:12:50.959825Z","iopub.execute_input":"2022-11-26T23:12:50.960218Z","iopub.status.idle":"2022-11-26T23:12:51.019811Z","shell.execute_reply.started":"2022-11-26T23:12:50.960180Z","shell.execute_reply":"2022-11-26T23:12:51.018486Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670019670107,"user_tz":180,"elapsed":2,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}},"outputId":"207c6599-a19a-442d-8280-04d0acc65e61"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["#train_1_ds = TensorDataset(torch.from_numpy(train_x_tok).type(torch.float32), torch.from_numpy(train_y.to_numpy()))\n","#train_2_ds = TensorDataset(torch.from_numpy(train_x_tok_2).type(torch.float32), torch.from_numpy(train_y_2))\n","train_ds = TensorDataset(torch.from_numpy(train_x_padded).type(torch.float32), torch.from_numpy(train_y))\n","#train_ds = torch.utils.data.ConcatDataset([train_1_ds, train_2_ds])\n","val_ds = TensorDataset(torch.from_numpy(val_x_padded).type(torch.float32), torch.from_numpy(val_y))\n","test_ds = TensorDataset(torch.from_numpy(test_x_padded).type(torch.float32), torch.from_numpy(test_y))\n","\n","batch_size = 256\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n","val_dl = DataLoader(val_ds, shuffle=True, batch_size=batch_size)\n","test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"aMgDKasuh1H7","execution":{"iopub.status.busy":"2022-11-26T23:12:59.364000Z","iopub.execute_input":"2022-11-26T23:12:59.364678Z","iopub.status.idle":"2022-11-26T23:13:00.634718Z","shell.execute_reply.started":"2022-11-26T23:12:59.364642Z","shell.execute_reply":"2022-11-26T23:13:00.633704Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670028804057,"user_tz":180,"elapsed":763,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["vocab_size=1996"],"metadata":{"id":"_do7o2NaWMZv","execution":{"iopub.status.busy":"2022-11-26T23:13:16.568293Z","iopub.execute_input":"2022-11-26T23:13:16.568685Z","iopub.status.idle":"2022-11-26T23:13:16.573728Z","shell.execute_reply.started":"2022-11-26T23:13:16.568653Z","shell.execute_reply":"2022-11-26T23:13:16.572639Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670028805388,"user_tz":180,"elapsed":2,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":["# LSTM model"],"metadata":{"id":"pNWO4FgSUjsW"}},{"cell_type":"code","source":["class TweetsLSTM(nn.Module):\n","    def __init__(self,no_layers,hidden_dim,input_dim,drop_prob=0.5):\n","        super(TweetsLSTM,self).__init__()\n"," \n","        #self.output_dim = output_dim\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.no_layers = no_layers\n","    \n","        #print(type(self.no_layers), type(self.input_dim), type(self.hidden_dim))\n","        \n","        # embedding and LSTM layers\n","        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm\n","        self.lstm_layers = nn.LSTM(input_size=self.input_dim,hidden_size=self.hidden_dim,\n","                           num_layers=no_layers, batch_first=True)\n","        \n","        \n","        # dropout layer\n","        self.dropout_layer = nn.Dropout(p=drop_prob, inplace=True)\n","    \n","        # linear and sigmoid layer\n","        self.linear_layer = nn.Linear(self.hidden_dim, 1)\n","        self.sigmoid_layer = nn.Sigmoid()\n","\n","    def forward(self,x):\n","        #print(\"x:\", x.shape, x.dtype)\n","        batch_size, _seq1 , _seq2 = x.size()\n","        \n","        h_1 = torch.zeros(self.no_layers, batch_size, self.hidden_dim).to(device)\n","        c_1 = torch.zeros(self.no_layers, batch_size, self.hidden_dim).to(device)\n","        \n","        hc_1 = (h_1, c_1)\n","        \n","        #print(\"hidden:\",hidden[0].shape, hidden[0].dtype)\n","        # embeddings and lstm_out\n","        #embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n","        #print(\"emb:\",embeds.shape)  #[50, 500, 1000]\n","        #print(embeds[0])\n","        #print(\"emb: \",embeds)\n","\n","        lstm_out, (h_1, c_1) = self.lstm_layers(x, hc_1)\n","        #print(\"lstm out:\",lstm_out.shape)\n","        #lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n","        \n","        # dropout and fully connected layer\n","        out = self.dropout_layer(h_1) #(h_1) lstm_out\n","        #print(out.contiguous().view(batch_size,-1))\n","        #out = self.fc(out.contiguous().view(batch_size,-1))\n","        #print(\"out:\", out,out.shape)\n","        lin_out = self.linear_layer(out)\n","        #print(\"lin_out: \", lin_out.shape)\n","        \n","        \n","        # sigmoid function\n","        sig_out = self.sigmoid_layer(lin_out)\n","        #print(\"out2:\", sig_out.shape)\n","        # reshape to be batch_size first\n","        #sig_out = sig_out.view(batch_size, -1)\n","        #print(\"sig_out: \", sig_out.shape)\n","\n","        #sig_out = sig_out[:, -1]\n","        #print(sig_out)\n","        # # reshape to be batch_size first\n","        #sig_out = out.view(batch_size, -1)\n","        #print(\"out3:\", sig_out.shape)\n","        #sig_out = sig_out[:, -1] # get last batch of labels\n","        #print(\"sig_out:\", sig_out.shape)\n","        \n","        #sig_out = out.view(batch_size,-1)\n","        sig_out_f = sig_out[-1,:,:]\n","        #print(sig_out.shape,sig_out)\n","        # # return last sigmoid output and hidden state\n","\n","        #sig_out = torch.max(out,1)\n","        # print(\"sig_out:\",sig_out.shape, sig_out)\n","        #sig_out = torch.max(sig_out,1)\n","        #print(\"sig_out:\",sig_out.shape, sig_out_f.shape)\n","        #return sig_out[1], hidden\n","        return sig_out_f\n","\n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        h0 = torch.zeros(2*self.no_layers,batch_size,self.hidden_dim).to(device)\n","        c0 = torch.zeros(2*self.no_layers,batch_size,self.hidden_dim).to(device)\n","        hidden = (h0,c0)\n","        return hidden"],"metadata":{"id":"joB1aqaTLeeC","execution":{"iopub.status.busy":"2022-11-26T23:17:46.489018Z","iopub.execute_input":"2022-11-26T23:17:46.489420Z","iopub.status.idle":"2022-11-26T23:17:46.500400Z","shell.execute_reply.started":"2022-11-26T23:17:46.489387Z","shell.execute_reply":"2022-11-26T23:17:46.499052Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670028808343,"user_tz":180,"elapsed":3,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["no_layers = 2\n","#vocab_size = len(vocab_to_int) + 1 #extra 1 for padding\n","#vocab_size = 128\n","embedding_dim = 64\n","input_dim = 1\n","output_dim = 3\n","hidden_dim = 50 #256\n","\n","\n","model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3).to(device)\n","\n","#print(train_x_tok.shape)\n","dataiter = iter(train_dl)\n","print('sample input: ', dataiter.next()[0].size())\n","print('sample output: ', dataiter.next()[1].size())\n","print(model)\n","print(vocab_size)\n","#summary(model, (4, max_len, 1),dtypes=[torch.int])\n","summary(model, input_data=torch.tensor(np.ones((4, 200, 1))).type(torch.float32).to(device))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LxyorjhPRys","outputId":"95b930a6-0f55-4425-8fb9-1f74e7f4121c","execution":{"iopub.status.busy":"2022-11-26T23:17:47.687923Z","iopub.execute_input":"2022-11-26T23:17:47.688324Z","iopub.status.idle":"2022-11-26T23:17:48.683098Z","shell.execute_reply.started":"2022-11-26T23:17:47.688283Z","shell.execute_reply":"2022-11-26T23:17:48.682082Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670028808623,"user_tz":180,"elapsed":2,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["sample input:  torch.Size([256, 280])\n","sample output:  torch.Size([256])\n","TweetsLSTM(\n","  (lstm_layers): LSTM(1, 50, num_layers=2, batch_first=True)\n","  (dropout_layer): Dropout(p=0.3, inplace=True)\n","  (linear_layer): Linear(in_features=50, out_features=1, bias=True)\n","  (sigmoid_layer): Sigmoid()\n",")\n","1996\n"]},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","TweetsLSTM                               [4, 1]                    --\n","├─LSTM: 1-1                              [4, 200, 50]              31,000\n","├─Dropout: 1-2                           [2, 4, 50]                --\n","├─Linear: 1-3                            [2, 4, 1]                 51\n","├─Sigmoid: 1-4                           [2, 4, 1]                 --\n","==========================================================================================\n","Total params: 31,051\n","Trainable params: 31,051\n","Non-trainable params: 0\n","Total mult-adds (M): 24.80\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.32\n","Params size (MB): 0.12\n","Estimated Total Size (MB): 0.45\n","=========================================================================================="]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["# loss and optimization functions\n","lr=0.00001\n","\n","def BCELoss_class_weighted(weights):\n","    def loss(input, target):\n","        input = torch.clamp(input,min=1e-7,max=1-1e-7)\n","        bce = - weights[1] * target * torch.log(input) - (1 - target) * weights[0] * torch.log(1 - input)\n","        return torch.mean(bce)\n","    return loss\n","\n","weights = [len(train_y)/(2*(len(train_y)-train_y.sum())), len(train_y)/(2*train_y.sum())]\n","criterion = BCELoss_class_weighted(weights)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","# function to predict accuracy\n","def acc(pred,label):\n","    #pred = torch.round(pred.squeeze())\n","    #print(pred, label, torch.sum(pred == label.squeeze()).item())\n","    return torch.sum(((pred >= 0.5).type(torch.float32) == label.squeeze()).type(torch.float32)).item()"],"metadata":{"id":"00M0z3b8PRnC","execution":{"iopub.status.busy":"2022-11-26T23:17:52.294045Z","iopub.execute_input":"2022-11-26T23:17:52.295080Z","iopub.status.idle":"2022-11-26T23:17:52.306584Z","shell.execute_reply.started":"2022-11-26T23:17:52.295014Z","shell.execute_reply":"2022-11-26T23:17:52.305486Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670028811838,"user_tz":180,"elapsed":2,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["clip = 5\n","epochs = 50\n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","print(len(train_dl.dataset))\n","print(len(val_dl.dataset))\n","\n","\n","\n","for epoch in range(epochs):\n","    print(\"epoch:\", epoch)\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    for inputs, labels in train_dl:\n","        #print(inputs.shape)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","      \n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        \n","        # calculate the loss and perform backprop\n","        #print(\"output:\",output.shape, output[0].shape, output[0].dtype)\n","        #print(\"labels:\",labels.shape, labels.dtype)\n","        #print(output, torch.max(labels,1)[1])\n","        #print(output.T, labels.type(torch.float32))\n","        loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        #accuracy = acc(output,labels)\n","        accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in val_dl:\n","            #print(inputs.shape)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            output = model(inputs)\n","            #print(\"output:\",output.squeeze())\n","            #print(\"labels:\",labels.long())\n","            val_loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","            val_acc += accuracy\n","            epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_dl.dataset)\n","    epoch_val_acc = val_acc/len(val_dl.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), f'model_{epoch}_loss_00001-{epoch_val_loss}_acc-{epoch_val_acc}')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"id":"YJzL2_26NXFW","outputId":"cbf8bc4a-f124-4996-bba4-64998ead4c1d","execution":{"iopub.status.busy":"2022-11-26T23:17:54.187019Z","iopub.execute_input":"2022-11-26T23:17:54.187409Z","iopub.status.idle":"2022-11-27T01:25:46.754077Z","shell.execute_reply.started":"2022-11-26T23:17:54.187376Z","shell.execute_reply":"2022-11-27T01:25:46.752901Z"},"trusted":true,"executionInfo":{"status":"error","timestamp":1670028814094,"user_tz":180,"elapsed":322,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["1167515\n","145938\n","epoch: 0\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-d85e80bbea5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-91-c24b3ce5bf09>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(\"x:\", x.shape, x.dtype)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_seq1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_seq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mh_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"]}]},{"cell_type":"code","source":["import plotly.graph_objects as go\n","\n","fig = go.Figure()\n","\n","# Add traces\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_loss,\n","                    mode='lines+markers',\n","                    name='loss'))\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_acc,\n","                    mode='lines+markers',\n","                    name='acc'))\n","fig.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"oMRk7kXvU3ZP","outputId":"9e25c31d-9bbd-4fcd-d0f8-dc87fb63e3fc","execution":{"iopub.status.busy":"2022-11-27T01:26:03.208421Z","iopub.execute_input":"2022-11-27T01:26:03.208796Z","iopub.status.idle":"2022-11-27T01:26:03.313119Z","shell.execute_reply.started":"2022-11-27T01:26:03.208768Z","shell.execute_reply":"2022-11-27T01:26:03.312195Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1670025939701,"user_tz":180,"elapsed":19,"user":{"displayName":"sandra nihama","userId":"01926653818055412719"}}},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"cc837a12-bec5-4a12-892c-f3ec18274852\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cc837a12-bec5-4a12-892c-f3ec18274852\")) {                    Plotly.newPlot(                        \"cc837a12-bec5-4a12-892c-f3ec18274852\",                        [{\"mode\":\"lines+markers\",\"name\":\"loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.6940336261372311,0.6939980800375408,0.6938670894537549,0.6939718996506841,0.6939904638594645,0.6938576606885056,0.6940008469258976,0.6939475611048137,0.69391552744781,0.6939069086997578,0.6939440456845068,0.6939033098016049,0.6939193520704766,0.6939039699452473,0.6939053974268626,0.6939269313678524,0.6939327473916264,0.6939500816865097,0.693883372021808,0.6939875113661095,0.6940090402921598,0.693949400908481,0.6939894787895377,0.6939962367861027,0.6938800444005353,0.6938871483234436,0.6939256940360241,0.6939248035708402,0.6939282287744761,0.6939747458377707,0.6940770282440286,0.6939707210354383,0.6939301694515606,0.6940132176844724,0.6939231746558241,0.6938790856068016,0.6940159219383253,0.693953418554077,0.6939996007134474,0.6939681068937785,0.6939712046636604,0.6938582894887766,0.6939028744944139,0.6939112627119688,0.6939306062214423,0.693950548546028,0.6938901487721569,0.6939283426553925,0.6939936404056867,0.6939291451501804],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"acc\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.3347243349915718,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.6652756650084283,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.3347243349915718,0.6652756650084283,0.3347243349915718,0.3347243349915718,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.6652756650084283,0.6652756650084283],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('cc837a12-bec5-4a12-892c-f3ec18274852');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3)\n","model.load_state_dict(torch.load('/kaggle/working/model_loss_00001-0.4798233907558872_acc-0.7717592402253012'))\n","model.to(device)\n","model.eval()\n","\n","# model.load_state_dict(torch.load('model_weights.pth'))"],"metadata":{"id":"tlXKxe2hxNKz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5db0be20-05a3-45c2-e190-83f016b0bcc8","execution":{"iopub.status.busy":"2022-11-27T01:37:16.742668Z","iopub.execute_input":"2022-11-27T01:37:16.743082Z","iopub.status.idle":"2022-11-27T01:37:16.758813Z","shell.execute_reply.started":"2022-11-27T01:37:16.743047Z","shell.execute_reply":"2022-11-27T01:37:16.757829Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"<class 'int'> <class 'int'> <class 'int'>\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"TweetsLSTM(\n  (lstm_layers): LSTM(1, 50, num_layers=2, batch_first=True)\n  (dropout_layer): Dropout(p=0.3, inplace=True)\n  (linear_layer): Linear(in_features=50, out_features=1, bias=True)\n  (sigmoid_layer): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n","\n","def predict_text(inputs):\n","    output = model(inputs)\n","    return output\n","\n","corrects = 0\n","total = 0\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","all_pred_bin = np.empty((1,0))\n","all_labels = np.empty((1,0))\n","\n","for inputs, labels in test_dl:\n","    #print(inputs.shape)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred_test = predict_text(inputs)\n","    #print(torch.squeeze(pred_test, 1).type(torch.float32))\n","    all_pred_bin = np.append(all_pred_bin, (torch.squeeze(pred_test, 1).type(torch.float32) >= 0.5).type(torch.int).detach().cpu().numpy())\n","    all_labels = np.append(all_labels, labels.detach().cpu().numpy())\n","    #print(torch.squeeze(pred_test.T, 0), labels.type(torch.float32))\n","    corrects += acc(torch.squeeze(pred_test, 1).type(torch.float32), labels.type(torch.float32))#acc(pred_test, labels)\n","    #print(corrects)\n","    total += len(pred_test)\n","\n","print(precision_recall_fscore_support(all_labels, all_pred_bin, average='binary', pos_label=0))\n","print(confusion_matrix(all_labels, all_pred_bin))\n","print(classification_report(all_labels, all_pred_bin))\n","\n","print(corrects/total)\n","print(all_pred_bin.shape, all_pred_bin)\n","print(all_labels.shape, all_labels)\n","print(\"f1: \", f1_score(all_labels, all_pred_bin))\n","print(\"recall: \", recall_score(all_labels, all_pred_bin))\n","print(\"precision: \", precision_score(all_labels, all_pred_bin))\n","print(\"accuracy: \", accuracy_score(all_labels, all_pred_bin))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TklfNz7-NW3m","outputId":"1034038a-810b-4664-9f94-d70490c2f00d","execution":{"iopub.status.busy":"2022-11-27T01:37:18.743037Z","iopub.execute_input":"2022-11-27T01:37:18.743975Z","iopub.status.idle":"2022-11-27T01:37:26.084458Z","shell.execute_reply.started":"2022-11-27T01:37:18.743925Z","shell.execute_reply":"2022-11-27T01:37:26.083226Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"(0.6341416907902719, 0.7524734146491968, 0.6882584237954584, None)\n[[36583 12034]\n [21106 76217]]\n              precision    recall  f1-score   support\n\n         0.0       0.63      0.75      0.69     48617\n         1.0       0.86      0.78      0.82     97323\n\n    accuracy                           0.77    145940\n   macro avg       0.75      0.77      0.75    145940\nweighted avg       0.79      0.77      0.78    145940\n\n0.7729203782376319\n(145940,) [1. 1. 1. ... 1. 1. 0.]\n(145940,) [1. 1. 1. ... 1. 1. 1.]\nf1:  0.8214189487751516\nrecall:  0.7831345108556045\nprecision:  0.8636389389355361\naccuracy:  0.7729203782376319\n","output_type":"stream"}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix(all_labels, all_pred_bin), display_labels=['racista','não racista'])\n","disp.plot(cmap='Blues')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"ZQHo4vGMrkTq","outputId":"c79b9655-953e-4b4e-c1ed-5d64637e8ede","execution":{"iopub.status.busy":"2022-11-27T01:36:55.031263Z","iopub.execute_input":"2022-11-27T01:36:55.031716Z","iopub.status.idle":"2022-11-27T01:36:55.351100Z","shell.execute_reply.started":"2022-11-27T01:36:55.031673Z","shell.execute_reply":"2022-11-27T01:36:55.350092Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXYAAAEGCAYAAABxfL6kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAArH0lEQVR4nO3dd5wV1fnH8c+zS+8sPYCAuBZEQEEsJNgRbGBi7BErsWCL/mwpqGhCqokaTVARsHdFBBERoqIiIAiCIoggIH0RpLPs8/tjzq7Xdctd2Tr3+/Y1rztz5sy5Z+7ic889c+aMuTsiIhIfaRVdARERKV0K7CIiMaPALiISMwrsIiIxo8AuIhIz1Sq6AnFTt2GGN27ZuqKrISXQol7Niq6ClMDSpUtYt26d7UkZ6Q3auWdvSyqvb1s7wd377sn7lTcF9lLWuGVrBj/4ckVXQ0rgut4dK7oKUgK9Duuxx2V49nZq7n92Unm3z7qv6R6/YTlTYBeR1GOA7VGjv1JTYBeR1GTxvcSowC4iqUktdhGRODFIS6/oSpQZBXYRST2GumJEROLF1BUjIhI7arGLiMSMWuwiInFisW6xx/fMREQKY0SjYpJZiivKbD8zm52wbDKz68wsw8wmmtnC8No45Dczu9fMFpnZHDM7JKGsgSH/QjMbmJDe3czmhmPuNSv654YCu4ikoNBiT2YphrsvcPdu7t4N6A5sBV4CbgEmuXsmMClsA/QDMsMyCHgQwMwygCHAYUBPYEjul0HIc1nCcUXOXaPALiKpKc2SW0rmOOALd18K9AdGhfRRwICw3h8Y7ZEPgEZm1go4EZjo7lnuvgGYCPQN+xq4+wcePct0dEJZBVIfu4iknpKNY29qZjMStoe7+/BC8p4NPBXWW7j7yrC+CmgR1lsDyxKOWR7SikpfXkB6oRTYRSQ1JT8qZp27FzulpJnVAE4Dbs2/z93dzLxkFfzx1BUjIinISu3iaYJ+wEfuvjpsrw7dKITXNSF9BdA24bg2Ia2o9DYFpBdKgV1EUlMpXTxNcA7fdcMAjAFyR7YMBF5JSL8gjI45HNgYumwmAH3MrHG4aNoHmBD2bTKzw8NomAsSyiqQumJEJPVY6U4pYGZ1gROAXyckDwOeNbNLgKXAmSF9HHASsIhoBM1FAO6eZWZDgekh353unhXWrwRGArWB8WEplAK7iKSmUrxByd23AE3ypa0nGiWTP68DVxVSzghgRAHpM4DOydZHgV1EUpOmFBARiZN4TymgwC4iqSd3SoGYUmAXkRSkFruISPyoj11EJGbUYhcRiRm12EVEYsTUxy4iEjuWpsAuIhIbBhTzEKIqTYFdRFKPhSWmFNhFJAWZWuwiInGjwC4iEjNpungqIhIj6mMXEYkXUx+7iEj8KLCLiMSMAruISMwosIuIxImBpSmwi4jEhi6eiojEkAK7iEjcxDeuK7CLSAoytdhFRGInzoE9vpMliIgUwjDS0tKSWpIqz6yRmT1vZp+Z2admdoSZZZjZRDNbGF4bh7xmZvea2SIzm2NmhySUMzDkX2hmAxPSu5vZ3HDMvVbMt5ICu4ikJktySc6/gNfdfX+gK/ApcAswyd0zgUlhG6AfkBmWQcCDAGaWAQwBDgN6AkNyvwxCnssSjutbVGUU2EUk9YQ+9mSWYosyawj0Bh4BcPed7v4N0B8YFbKNAgaE9f7AaI98ADQys1bAicBEd89y9w3ARKBv2NfA3T9wdwdGJ5RVIAV2EUlJJQjsTc1sRsIyKF9RHYC1wKNmNsvMHjazukALd18Z8qwCWoT11sCyhOOXh7Si0pcXkF4oXTwVkZRUgoun69y9RxH7qwGHAFe7+zQz+xffdbsA4O5uZv7jalpyarGLSEqyNEtqScJyYLm7TwvbzxMF+tWhG4XwuibsXwG0TTi+TUgrKr1NAemFUos9hWTvyubRfz/L7uzd5OTkcECXTI7peySLP/+KiWPfwd2pUaM6A845kYymjcjOzublJyfw9fLV1KlbmzN+dRKNMhqy4qtVvPrcm1Gh7hx14hEccNA+ALz/v4+YNW0umNGiZVP6n92HatX1z+zHGnzn40x49xOaNq7P+8/8FoANG7dw8W0j+GplFnu1yuDRP11CowZ1eHfm55x7w3Da/aQJAKce042bLuvHwiWrufi2EXllLv16PbcOOpkrzj2GuZ8v54ZhT7N56w72atWE4UMH0qBe7Qo51/KUbP95Mtx9lZktM7P93H0BcBwwPywDgWHh9ZVwyBhgsJk9TXShdKO7rzSzCcAfEy6Y9gFudfcsM9tkZocD04ALgPuKqlNK/R9nZj2AC9z9mkL2tweOdPcny7Vi5SS9WjoDrziDGjVrsHv3bh69/1kyD+jAay9M4uyLT6NZiyZMn/oxb0+cxoBzTmTWtHnUqlOTa267mE9mLeDNse9yxgUn07xlEwZddy5p6Wl8u2kz//n74+zXaW82b97Kh+/O4sqbBlK9ejWeGz2WT2YtoFvPAyv61Kusc045nMvOPIrLh4zOS7tn1ER6H7of11/Yh3tGvsE9o97gjqsHAHDEwR155p4rvldGZvsWvPPkrQDs3p1Dp5N+y8nHdAXg2rueZOi1p9OreyaPj3mf+x6bxG+vOKV8Tq6ClfI49quBJ8ysBrAYuIioR+RZM7sEWAqcGfKOA04CFgFbQ15CAB8KTA/57nT3rLB+JTASqA2MD0uhqnRXTBgPmvQ5uPuMwoJ60B44d48rVkmZGTVq1gAgZ3cOu3fn5KXv2L4TgO3bd1C/YV0AFnzyBV17dAKgU5dMFi/8Cneneo3qpKVHH3v2rt1YwpiwnN05ZO/KJmd3Drt2ZlO/Yb1yO7846nXIPjRuUOd7aeP/N4dzTjkMgHNOOYxxU+YkXd7/pi+gfZtm7NUqA4BFX63hyEOiX1tH99yfVyfPLp2KVwGlNSoGwN1nu3sPd+/i7gPcfYO7r3f349w9092Pzw3SYTTMVe7e0d0PcvcZCeWMcPd9wvJoQvoMd+8cjhkcRscUqsq12EOregLRT5LuwIdmdhDRN9nz7j4k5DuUaGxpXWAH0c+j7sCN7n6KmR0V9gM40XClYcABZjabaHjSS8BjoQyAwe7+XlmfY1nKyclh+D1PkrXuGw7t1ZU27Vpx6pnH8+TDL1OtejVq1qrBpdecDcCmTZtp2Kg+AGnpadSqXZNtW7ZTp15tli9dyZhn3uCbDd9y+rl9SUtPo0HDehxxdHfuGfow1atXo+O+7ei4X7uKPN1YWpP1LS2bNgSgRZMGrMn6Nm/f9Llf8tNz/0TLpg0Zeu3pHNCx1feOffGNmfzixO552/vv3Ypx/5vDyUd35ZVJH7Fi9YbyOYnKIL43nla9wB5kAgPd/QMzywg/YdKBSWbWBfgMeAY4y92nm1kDYFu+Mm4ErnL3qWZWD9hOdCX7Rnc/BcDM6gAnuPt2M8sEngJ+cHU8DH8aBNCo+U/K5IRLS1paGpffcD7bt23nmUdfZc3KdXzw9izOvXQAbdq1YurkGUx45W1OO+uEIstp064VV940kLWr1/PyUxPI3L89u3Zls2DeYq797cXUql2T50a9xpyZn9Kl+wHldHapJ2pVRutd9mvLnDFDqVenJm9Mncf5/zecmS8Oycu7c1c249+eyx+uOi0v7f4/nMctf3uevz7yOv16H0T16unlfQoVRlMKVD5Lw8B+gDPN7CNgFnAg0AnYD1jp7tMB3H2Tu2fnK2Mq8A8zuwZoVMB+gOrAQ2Y2F3gulP0D7j48/AzrUbdRxh6fXHmoVbsW7fdpy8LPlrD667W0aRe17Dp325dlS78GoEGDemz8JmoN5uzOYfu2HdSuW+t75TRr0YQaNWuwZtU6Fi/8ikYZDahbrw7p6ekc0GUfli35unxPLAU0z6jPqnUbAVi1biPNGke/qhrUq029OjUB6NPrQHZl72b9N5vzjnvzvfl03b8tzZs0yEvbt31LXrx/MFMeu5lf9OlOh9bNyvFMKo4ZpKVZUktVVFUD+xYAM+tA1PI+zt27AK8BtYo6MJe7DwMuJerCmWpm+xeQ7XpgNdEtwj2AGnte9YqzZfNWtm/bDsCuXdks/nwpzVpksH3bDtavjX6Cf/H5VzRrHn057Xvg3nw8Yz4A8+cspENmW8yMDes3khP657/J2sS6NVk0atyQho3qs2LpSnbt3IW78+XCr2javGp80VUlfXsfxFNjo5F1T42dRr+jugCwet0mcrteZ85bQk6Ok9Gwbt5xz0+YwS/6dP9eWWtDN05OTg5/GzGBi37x0/I4hUoguf71qtqqr6pdMbkaEAX5jWbWgmgOhinAAqCVmR0aumLqk68rxsw6uvtcYG7oj9+f6K6v+gnZGhKNT80JE/JU6d+pmzdt4eWnJpDjjrtzYNd92bfT3px65gk8O/JVzIxadWrRP3TDHHJYZ1568nXu/eMIatepxRm/OgmAr75cwdS3ppOWno6ZcfLPj6VOvdrUqVebA7pk8t9/PEFaehqtWjej+xEHVeQpV3mX/PZRps5cyPpvNnPgyb/jlkEncf3AE7jo1hE8PuZ92rbM4NE/XQzAK2/N4tHn3yG9Wjq1a1bnkbsvygtMW7btYMqHn3HPbed8r/wXJszg4effBuCUo7tx3qmHl+8JVqAqGrOTYsVcXK10wsXTse7eOWyPBI4kCsobgTHuPjIE6/uIWuTbgOOJWt25F0/vA44BcoB5wIVhfQLQhGho0VjgBaKLq68T9ckXOcyjzX4H+eAHXy6185Wyd13vjhVdBSmBXof1YObMGXsUlmu13NfbDSxyKHiez//Sd2Yxd55WOlWuxe7uS4DOCdsXFpJvOpC/+TElLLj71YW8xbH5trskrN+cdEVFpPKyeLfYq1xgFxHZUwZV9sJoMhTYRSQlKbCLiMSJumJEROLFiPcNSgrsIpKCqu4Y9WQosItISopxXFdgF5EUZLp4KiISK+pjFxGJoRjHdQV2EUlNarGLiMRMjOO6AruIpCBTi11EJFaMqvsQjWQosItISopxg12BXURSk7piRETiRJOAiYjEi25QEhGJoTgH9rSKroCISEVIS7OklmSY2RIzm2tms81sRkjLMLOJZrYwvDYO6WZm95rZIjObY2aHJJQzMORfaGYDE9K7h/IXhWOLrJgCu4ikntDHnsxSAse4e7eEB1/fAkxy90xgUtgG6AdkhmUQ8CBEXwTAEOAwoCcwJPfLIOS5LOG4vkVVRIFdRFKOhfnYk1n2QH9gVFgfBQxISB/tkQ+ARmbWCjgRmOjuWe6+AZgI9A37Grj7B+7uwOiEsgqkwC4iKakELfamZjYjYRlUQHEOvGFmMxP2t3D3lWF9FdAirLcGliUcuzykFZW+vID0QuniqYikpLTkW+PrErpXCvNTd19hZs2BiWb2WeJOd3cz8x9Tzx9DLXYRSTlmpXvx1N1XhNc1wEtEfeSrQzcK4XVNyL4CaJtweJuQVlR6mwLSC6XALiIpKc2SW4pjZnXNrH7uOtAH+AQYA+SObBkIvBLWxwAXhNExhwMbQ5fNBKCPmTUOF037ABPCvk1mdngYDXNBQlkFUleMiKSkUhzH3gJ4KZRXDXjS3V83s+nAs2Z2CbAUODPkHwecBCwCtgIXAbh7lpkNBaaHfHe6e1ZYvxIYCdQGxoelUIUGdjO7j+iCQIHc/ZqiChYRqcxKK667+2KgawHp64HjCkh34KpCyhoBjCggfQbQOdk6FdVin5FsISIiVYkRDXmMq0IDu7uPStw2szruvrXsqyQiUvZiPB178RdPzewIM5sPfBa2u5rZA2VeMxGRsmLJjYipqg/jSGZUzD+J7ohaD+DuHwO9y7BOIiJlyojGsSezVEVJjYpx92X5riDvLpvqiIiUjyoas5OSTGBfZmZHAm5m1YFrgU/LtloiImUr1aftvZxoaE5r4GugG4UM1RERqQqSnSemqsb+Ylvs7r4OOK8c6iIiUm7Sq2rUTkIyo2L2NrNXzWytma0xs1fMbO/yqJyISFkph2l7K0wyXTFPAs8CrYCfAM8BT5VlpUREylI0KqZ05oqpjJIJ7HXc/TF3zw7L40Ctsq6YiEiZSbK1XlVb7EXNFZMRVseb2S3A00Rzx5xFNImNiEiVVUVjdlKKung6kyiQ557+rxP2OXBrWVVKRKSsVdXWeDKKmiumQ3lWRESkvBiQXlU70JOQ1J2nZtYZ6ERC37q7jy6rSomIlLX4hvUkAruZDQGOJgrs44B+wLtET8oWEalyzEr0zNMqJ5lRMWcQTRa/yt0vIppQvmGZ1kpEpIyl9J2nwDZ3zzGzbDNrQPRA1rbFHSQiUpml5MXTBDPMrBHwENFImc3A+2VZKRGRshbjuJ7UXDFXhtX/mNnrQAN3n1O21RIRKTtmlpqjYszskKL2uftHZVMlEZGyl6pdMX8vYp8Dx5ZyXWKhQc3q9N2neUVXQ0qg8aGDK7oKUgI7FnxVKuUkM3KkqirqBqVjyrMiIiLlxUjdFruISGzFuItdgV1EUo+ZphQQEYmdGMf1pJ6gZGZ2vpn9IWzvZWY9y75qIiJlpzTvPDWzdDObZWZjw3YHM5tmZovM7BkzqxHSa4btRWF/+4Qybg3pC8zsxIT0viFtUZhCvVjJXBh+ADgCOCdsfwv8O7nTFRGpfKInKFlSS5KuBT5N2P4zcI+77wNsAC4J6ZcAG0L6PSEfZtYJOBs4EOgLPBC+LNKJ4m0/ovm6zgl5i5RMYD/M3a8CtgO4+wagRhLHiYhUWmlJLsUxszbAycDDYduIhoM/H7KMAgaE9f5hm7D/uJC/P/C0u+9w9y+BRUDPsCxy98XuvpPogUf9kzm34uwK3xoeKt0MyEniOBGRSqsEXTFNzWxGwjIoX1H/BG7iu7jYBPjG3bPD9nKgdVhvDSwDCPs3hvx56fmOKSy9SMlcPL0XeAlobmZ3E832+LskjhMRqZRKOKXAOnfvUUg5pwBr3H2mmR1dStXbY8nMFfOEmc0kmrrXgAHu/mkxh4mIVGqlNCqmF3CamZ1E9CCiBsC/gEZmVi20ytsAK0L+FUSz4y43s2pEU6CvT0jPlXhMYemFSmZUzF7AVuBVYAywJaSJiFRJpXXx1N1vdfc27t6e6OLnW+5+HjCZqHcDYCDwSlgfE7YJ+99ydw/pZ4dRMx2ATOBDYDqQGUbZ1AjvMaa480umK+Y1vnuodS2gA7CA6OqtiEiVVMYzCtwMPG1mdwGzgEdC+iPAY2a2CMgiCtS4+zwzexaYD2QDV7n77qieNhiYAKQDI9x9XnFvnkxXzEGJ22HWxysLyS4iUvlZ6d+g5O5TgClhfTHRiJb8ebYDvyzk+LuBuwtIH0f0WNKklfjOU3f/yMwOK+lxIiKVicX4cdbJPMz6NwmbacAhwNdlViMRkTJmQLUYz9ubTIu9fsJ6NlGf+wtlUx0RkfKRstP2hhuT6rv7jeVUHxGRMheNiqnoWpSdoh6NV83ds82sV3lWSESkzJVggq+qqKgW+4dE/emzzWwM8BywJXenu79YxnUTESkzJZjgq8pJpo+9FtGdUcfy3Xh2BxTYRaRKMiA9RS+eNg8jYj7hu4Cey8u0ViIiZcpIS9HhjulAPSjw7BXYRaTKih5mXdG1KDtFBfaV7n5nudVERKS8lMGdp5VJUYE9xqctIqkuVS+eHldutRARKUcp2xXj7lnlWRERkfJUggdtVDklngRMRKSqM5J7LmhVpcAuIqnHUniuGBGRuIpvWFdgF5EUlPtovLhSYBeRlBTfsK7ALiIpyUjTqBgRkfjQqBgRkRjSqBgRkZiJb1hXYBeRVKRx7CIi8WJAugK7iEi8xDesx/vCsIhIocySW4ouw2qZ2Ydm9rGZzTOzO0J6BzObZmaLzOwZM6sR0muG7UVhf/uEsm4N6QvM7MSE9L4hbZGZ3ZLMuSmwi0jKiYY7WlJLMXYAx7p7V6Ab0NfMDgf+DNzj7vsAG4BLQv5LgA0h/Z6QDzPrBJwNHAj0BR4ws3QzSwf+DfQDOgHnhLxFUmAXkZRUGi12j2wOm9XD4sCxwPMhfRQwIKz3D9uE/cdZdBW3P/C0u+9w9y+BRUDPsCxy98XuvhN4OuQtkgK7iKQgS/o/oKmZzUhYBn2vpKhlPRtYA0wEvgC+cffskGU50DqstwaWAYT9G4Emien5jiksvUi6eCoiKaeEo2LWuXuPwna6+26gm5k1Al4C9t/jCu4hBXYRST1JdLOUlLt/Y2aTgSOARmZWLbTK2wArQrYVQFtguZlVAxoC6xPScyUeU1h6odQVIyIpqZRGxTQLLXXMrDZwAvApMBk4I2QbCLwS1seEbcL+t9zdQ/rZYdRMByAT+BCYDmSGUTY1iC6wjinu3NRiF5GUZKUzkr0VMCqMXkkDnnX3sWY2H3jazO4CZgGPhPyPAI+Z2SIgiyhQ4+7zzOxZYD6QDVwVungws8HABCAdGOHu84qrlAK7iKSc6EEbe16Ou88BDi4gfTHRiJb86duBXxZS1t3A3QWkjwPGlaReCuwikpL0BCURkZgppa6YSkmBPYWsXvsNd/7zObK+2YwZ9D+xJ2ed2ov/PvEG70z7lLQ0o3HDuvzuml/SrEkD3p42n+FPTCQtzUhPS+O6S0+ha6f2APx71Hjem7EAgIvOPJbjf9YFgKH/eo5Zn3xJvbq1APjdNWew794/qZDzjYN92jVnxB8vzttu95Mm/Gn4a2Q0rMtJvbuQ487arG+56o7HWbVuIw3r1+b+359PhzZN2b5zF1cPfYJPv1hJ6xaNePD2C2iWUR8HRr00lf8+PQWAzvu25h+3nE2tmtXJzs7hxj8/w0fzl1bMCZeT0uqKqazKPbCbWQuiu6d2ANPd/ffl+N53Am+7+5uF7B8AfO7u88urTuUpPT2Nay4+if06tmbL1h1cdMN99Oy6D+ef3ptfn9cHgGdfncqIZyZx85Wn06NLR37W8wDMjEVLVvLbvzzFMw/8hqkzPmPBF18z6p9Xs2vXbq767XCO6L4vdetEwXzwhf04ttdBFXmqsbFo6Rp6nzcMgLQ0Y/64u3lt8sd88+02/vif1wAYdNZR3HRpP34z7GluuOhE5n6+nF/d9BCZ7Vrw15vPZMCV95GdncPv/vkicxYsp16dmkwefTNTpn3Ggi9XccfVA/jLw+N58735nHBkJ+64ZgCnXv6vijztcmCxbrGX+3BHd1/t7se4e989CephDGhJ3/sPhQX1YADRfAyx1DSjAft1jG5aq1unJu3bNGdt1qa8gAywbceuvHmq69Sumbe+bfvOvKFfX361hm4Htqdaejq1a9WgY/tWvP/R5+V7MinoqEP3Y8nytSxbtYFvt2zPS69buybRiDnYr0NL3pkR/S0WLl3NXq0yaJZRn9XrNzFnwXIANm/dwedLVtGqWSMA3KF++IXVoF5tVq3dWI5nVUGSHOpYVbvhy6TFHmYsGw+8CxxJNKC+v7tvM7PLgEFADaL5EH7l7lvDMSOApsBa4CJ3/ypfubcDHYG9ga/M7FbgMaBuyDLY3d8LeW8GzgdygPHufouZjQTGuvvzZjYMOI1oaNEbwIth+ygz+x3wC6L5Hn5Q11L8qCrMytUb+Hzx1xy4b3Tvw38em8D4ybOoV7cW9991aV6+Ke/P48HHJrBh42b+/vto+G1mh5Y88vRbnDvgZ2zfsYuP5n5Bh7bN84757+NvMOKZt+jRpSNXDuxLjerq8SsNP+/TnRcmzMzb/t0Vp3L2yT3ZtHkbp15+LwCfLFzBKcd05f3ZX3BIp3a0bZnBT5o3Ym3Wt3nHtW2VQZf92jBz3hIAbvvH87xw31UMvfZ0zIy+l/y9XM+rolTRmJ0Uy/2mL9VCoyC9COjh7rPD+Mwx7v64mTVx9/Uh313Aane/z8xeBZ5391FmdjFwmrsPyFfu7cCpwE/Dl0QdIMfdt5tZJvCUu/cws37A74Hjw5dGhrtn5QZ2opsH3gP2d3c3s0bhrrGRhMAf3q/AuhZwvoOIvgBo1bpt93HvFTvMtEJt3baDK387nAt/eQxHH9H5e/tGPT+FnTt3cdm5J3wvfda8Lxnx9CTuGxoF/ZHPTuat9+bSqEFdGjesywGZbTj7tJ+yLmsTTRrXZ1f2bob9+0Vat2zCJWcfV27n9mMc0f/Wiq5CsapXS+fT8XdzxFl3fy9IA1x/YR9q1qjGsOHjqF+3Fn+64Qy67NeG+Yu+JrN9C669+0k++Ty6WbFu7RqM/e91/P3RCYyd/DEAw244g6kfLeLVybMZcPzBDDy9F6dfdX+5n2Oydix4lpyta/YoLh9w0MH+6EuTk8p7RGbjmUVNKVAZlWVXzJfuPjuszwTah/XOZvaOmc0FziOaphKi23CfDOuPAT8tpNwx7r4trFcHHgplPcd33SjHA4/mtq7dPStfGRuB7cAjZvZzoLBWeGF1/R53H+7uPdy9R6OMpoUUVTlkZ+/mtmFPcOJR3X4Q1AFOPKobU97/4RfTwQd24OvVWXyzaQsAF555DKP/eQ333nkJDuz1k+i8m2Y0wMyoUb0apxzXg/kLl/2gLCm544/sxMefLftBUAd4bvx0Tju2GwDfbtnO4Dsfp/d5w7h8yGiaNqrH0hXrAaiWnsaoP1/Gc6/PyAvqAOecchivTp4NwMtvzuKQTu3K/HwqBUtyqYLKMrDvSFjfzXfdPiOJukwOAu4AalEyWxLWrwdWA12BHkRdJsUK8zf0JJo28xTg9UKy7mldKxV35+77XqBd22ac0/9neenLvl6Xt/7OtPm0a90sSl+5Lq/vdsEXK9i5azcN69dh9+4cNoYAv2jJSr5YsoqeB2cCsC5rU957/W/aPDru1bJczi3uzjixBy+88V03zN5tm+Wt9zuqC58vWQ1EfeTVq6UDcMGAI3lv1qK8/vj7fn8eny9ZxQNPvvW9sleu3UivQ6K/X+9D92XxsrVlei6VRQlmd6xyKqLzsz6w0syqE7WCcye0eY/o9trHQvo7SZTVEFju7jlmNpDolluIps78g5k9kdgVk3uQmdUD6rj7ODObCiwOu74N9SuurlXSnE+X8vqUWXRs15ILrov6ZC8/vw+vvjmDr1asw8xo2bwRN10xAIAp781j/OSPqFYtnZo1qnHX/52DmZG9O5vLbx0ORBdhh1x/JtXSo4/+9n88w4ZNW8Ahs0OrvLLkx6tTqwZH99yf6//4VF7akMH9yWzXnJwcZ9mqLH7zp6eB6OLpA0N+heN8tnglVw99AoDDu+7N2ScfxryFK3j7ieghPEP/PYaJ783nuruf5E83nEG19DS278zmuoT3ibOqemE0GWXZxz7W3TuH7RuBeu5+u5ldAdxEdIF0GlDf3S80s3bAoxR/8XSzu/8tbGcCLxBNbP860fwK9cK+W4ALgJ3AOHe/LaGPfSrRpDy1iH5s/S307fcCHiL6tXEG0KeguhZ17p26HOJPjv3fj/nYpIJUhT52+U5p9bGPfmVKUnl7dmxU5frYyySwpzIF9qpHgb1qKbXAPmZKUnl77l31ArvGoYlIyjHTXDEiIrET37CuwC4iqSrGkV2BXURSUNUdypgMBXYRSUkx7mJXYBeR1GMosIuIxI66YkREYkYtdhGRmIlxXFdgF5EUVIVnbkyGAruIpCT1sYuIxIgeZi0iEkcxDuzl/jBrEZHKoLQetGFmbc1sspnNN7N5ZnZtSM8ws4lmtjC8Ng7pZmb3mtkiM5tjZocklDUw5F8YnjGRm97dzOaGY+41K3pMjwK7iKQks+SWJGQDN7h7J+Bw4Coz6wTcAkxy90xgUtgG6AdkhmUQ8GBUH8sAhgCHET3hbUjul0HIc1nCcX2LqpACu4ikpNJ65Km7r3T3j8L6t8CnQGugPzAqZBsFDAjr/YHRHvkAaGRmrYATgYnunuXuG4ieBNc37Gvg7h949ACN0QllFUh97CKSmpLvY29qZjMStoe7+/ACi4yeHncw0RPXWrj7yrBrFdAirLcGEp/yvjykFZW+vID0Qimwi0jKKeGDNtYl8wSl8CzlF4Dr3H1TYje4u7uZldvj6tQVIyIpqbS6YgDCA+9fAJ5w9xdD8urQjUJ4XRPSVwBtEw5vE9KKSm9TQHqhFNhFJDWVUmQPI1QeAT51938k7BoD5I5sGQi8kpB+QRgdcziwMXTZTAD6mFnjcNG0DzAh7NtkZoeH97ogoawCqStGRFJQqT5ooxfwK2Cumc0OabcBw4BnzewSYClwZtg3DjgJWARsBS4CcPcsMxsKTA/57nT3rLB+JTASqA2MD0uhFNhFJCWV1uyO7v4uhbftjysgvwNXFVLWCGBEAekzgM7J1kmBXURSjh60ISISQ5oETEQkZtRiFxGJmRjHdQV2EUlByc8DUyUpsItIiopvZFdgF5GUowdtiIjEkLpiRERiRsMdRUTiJr5xXYFdRFJTjOO6AruIpJ4SPPauSlJgF5GUVMzzoKs0BXYRSUnxDesK7CKSomLcYFdgF5FUVKoP2qh0FNhFJOVoPnYRkRhSYBcRiRl1xYiIxInGsYuIxIuh4Y4iIvET48iuwC4iKUl97CIiMaMHbYiIxI0Cu4hIvKgrRkQkRuJ+56m5e0XXIVbMbC2wtKLrUQaaAusquhJSInH9m7Vz92Z7UoCZvU70+SRjnbv33ZP3K28K7JIUM5vh7j0quh6SPP3NUldaRVdARERKlwK7iEjMKLBLsoZXdAWkxPQ3S1HqYxcRiRm12EVEYkaBXUQkZhTYpVhm1sPM7i1if3szO7c86xQ3ZtbCzCab2etmNrSc3/tOMzu+iP0DzKxTedZJ9oz62FOQmRnR3z6nlMo7GrjR3U8pjfLkxzOzau6eXcpljgTGuvvzpVmulB212FNEaFUvMLPRwCfAI2Y2w8zmmdkdCfkONbP3zOxjM/vQzOqb2dFmNjbsP8rMZodllpnVB4YBPwtp14f3esfMPgrLkRVz1pVL+Fw+NbOHwuf+hpnVDvsuM7Pp4XN/wczqJBzzlpnNMbNJZrZXAeXebmaPmdlU4LGiPn8zu9nM5ob3GRbSRprZGWF9mJnND+/3t3DsacBfw9+3Y2F1lUrE3bWkwAK0B3KAw8N2RnhNB6YAXYAawGLg0LCvAdF8QkcTtdgAXgV6hfV6+feH9DpArbCeCcyo6POvDEv4G2QD3cL2s8D5Yb1JQr67gKsTPu+BYf1i4OUCyr0dmAnULurzB/oB7wF18v0bGAmcATQBFvDdL/lGifsT3q/AumqpPIsmAUstS939g7B+ppkNIgrMrYBOgAMr3X06gLtvArDvz5Y0FfiHmT0BvOjuy+2HsylVB+43s27AbmDfsjmdKulLd58d1mcSBXuAzmZ2F9CI6AtzQkg/Avh5WH8M+Esh5Y5x921hvbDP/3jgUXffCuDuWfnK2AhsJ/o1NxYYW8h7FVZXqSTUFZNatgCYWQfgRuA4d+8CvAbUSqYAdx8GXArUBqaa2f4FZLseWA10BXoQ/RKQyI6E9d18N8PqSGCwux8E3EGSf48EWxLWf9Tn71HffE/geeAU4PVCsu5pXaWMKbCnpgZEgWCjmbUg+okO0c/wVmZ2KEDoX//erzoz6+juc939z8B0YH/gW6B+QraGRC3/HOBXRN09UrT6wEozqw6cl5D+HnB2WD8PeCeJsgr7/CcCFyX032ckHmRm9YCG7j6O6Muha9iV/+9bWF2lklBXTApy94/NbBbwGbCMqHsFd99pZmcB94WLetuIfr4nus7MjiHqr58HjA/ru83sY6LW3APAC2Z2AVGrbwtSnN8D04C14TU3kF4NPGpm/xf2XZREWQV+/u7+euiemWFmO4FxwG0Jx9UHXjGzWkRTlv8mpD8NPGRm1xD1xRdWV6kkNNxRRCRm1BUjIhIzCuwiIjGjwC4iEjMK7CIiMaPALiISMwrsUq7MbHeYc+QTM3tuT+YZyTfHycNFzUAY5rsp8Zw1ZrbEzH7wNPvC0vPl2VzC97rdzG4saR1F8lNgl/K2zd27uXtnYCdweeLO/DdEJcvdL3X3+UVkORrQZGSSEhTYpSK9A+wTWtPvmNkYYL6ZpZvZX8MMgnPM7NcQTTdsZvdbNEvlm0Dz3ILMbIqZ9QjrfcOshh+HGRHbE32BXB9+LfzMzJqFmQmnh6VXOLaJRbMuzjOzh4lu1CmSmb1sZjPDMYPy7bsnpE8ys2YhraNF867PDOdd0LQMIj+a7jyVChFa5v34bj6SQ4DO7v5lCI4b3f1QM6tJNCfNG8DBwH5EE5a1AOYDI/KV2wx4COgdyspw9ywz+w+w2d3/FvI9Cdzj7u9aNBXuBOAAYAjwrrvfaWYnA5ckcToXh/eoDUw3sxfcfT1Ql2hmxevN7A+h7MFED5m+3N0XmtlhRHeKHvsjPkaRAimwS3mrbWazw/o7wCNEXSQfuvuXIb0P0CW3/5xo7pNMoDfwlLvvBr42s7cKKP9w4O3csgqYwTDX8UCnhJkpG4S5UnoTZlN099fMbEMS53SNmZ0e1tuGuq4nmmrhmZD+OPBieI8jgecS3rtmEu8hkjQFdilv29y9W2JCCHCJ88kY0RzfE/LlO6kU65FGNDf99gLqkjSLnh51PHCEu281sykUPtuhh/f9Jv9nIFKa1MculdEE4IoweyBmtq+Z1QXeBs4KffCtgGMKOPYDoLdFUxMnzmCYf4bCN4gm2CLk6xZW3wbODWn9gMbF1LUhsCEE9f2JfjHkSiOaNItQ5rthjvsvzeyX4T3MzLoiUooU2KUyepio//wjM/sE+C/Rr8uXgIVh32jg/fwHuvtaYBBRt8fHfNcV8ipweu7FU+AaoEe4ODuf70bn3EH0xTCPqEvmq2Lq+jpQzcw+JXpE4AcJ+7YAPcM5HAvcGdLPAy4J9ZsH9E/iMxFJmmZ3FBGJGbXYRURiRoFdRCRmFNhFRGJGgV1EJGYU2EVEYkaBXUQkZhTYRURi5v8BM9Ur/thoAJ0AAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Dataset 2"],"metadata":{"id":"tW3SXPlg_YN5"}},{"cell_type":"code","source":["df_train = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-2/big_train_dataset_2.feather')\n","df_val = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-2/big_val_dataset_2.feather')\n","df_test = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-2/big_test_dataset_2.feather')\n","\n","df_train = shuffle(df_train)\n","df_val = shuffle(df_val)\n","df_test = shuffle(df_test)\n","\n","train_y = df_train['label']\n","train_x = df_train['text']\n","\n","val_y = df_val['label']\n","val_x = df_val['text']\n","\n","test_y = df_test['label']\n","test_x = df_test['text']\n"],"metadata":{"id":"07PgfvuKrmfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = train_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","val_x = val_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","test_x = test_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","\n","vocab_to_int = tweets_vocab(train_x)\n","train_x_tok, max_len1 = tweets_tok(train_x, vocab_to_int)\n","test_x_tok, _ = tweets_tok(test_x, vocab_to_int)\n","val_x_tok, _ = tweets_tok(val_x, vocab_to_int)\n","\n","max_len = 280\n","val_x_tok = padding(val_x_tok, max_len)\n","test_x_tok = padding(test_x_tok, max_len)\n","\n","num_words = 5000\n","\n","tokenizer = Tokenizer(num_words=num_words)\n","tokenizer.fit_on_texts(train_x)\n","\n","train_x_tokenized = tokenizer.texts_to_sequences(train_x)\n","test_x_tokenized = tokenizer.texts_to_sequences(test_x)\n","val_x_tokenized = tokenizer.texts_to_sequences(val_x)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","print(vocab_size)"],"metadata":{"id":"r4TIbv42_hSA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_padded = pad_sequences(train_x_tokenized, maxlen=max_length, padding='post')\n","test_x_padded = pad_sequences(test_x_tokenized, maxlen=max_length, padding='post')\n","val_x_padded = pad_sequences(val_x_tokenized, maxlen=max_length, padding='post')\n","\n","train_x_padded = np.array(train_x_padded)\n","val_x_padded = np.array(val_x_padded)\n","test_x_padded = np.array(test_x_padded)\n","\n","train_y = np.array(train_y)\n","val_y = np.array(val_y)\n","test_y = np.array(test_y)\n"],"metadata":{"id":"skdBO3Lb_g2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = TensorDataset(torch.from_numpy(np.expand_dims(train_x_padded, axis=2)).type(torch.float32), torch.from_numpy(train_y))\n","#train_ds = torch.utils.data.ConcatDataset([train_1_ds, train_2_ds])\n","val_ds = TensorDataset(torch.from_numpy(np.expand_dims(val_x_padded, axis=2)).type(torch.float32), torch.from_numpy(val_y))\n","test_ds = TensorDataset(torch.from_numpy(np.expand_dims(test_x_padded, axis=2)).type(torch.float32), torch.from_numpy(test_y))\n","\n","batch_size = 256\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n","val_dl = DataLoader(val_ds, shuffle=True, batch_size=batch_size)\n","test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"LZCypdHeA8G1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3).to(device)\n","\n","weights = [len(train_y)/(2*(len(train_y)-train_y.sum())), len(train_y)/(2*train_y.sum())]\n","criterion = BCELoss_class_weighted(weights)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"],"metadata":{"id":"pgD-QW6RA77M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clip = 5\n","epochs = 50\n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","print(len(train_dl.dataset))\n","print(len(val_dl.dataset))\n","\n","\n","\n","for epoch in range(epochs):\n","    print(\"epoch:\", epoch)\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    for inputs, labels in train_dl:\n","        #print(inputs.shape)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","      \n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        \n","        # calculate the loss and perform backprop\n","        #print(\"output:\",output.shape, output[0].shape, output[0].dtype)\n","        #print(\"labels:\",labels.shape, labels.dtype)\n","        #print(output, torch.max(labels,1)[1])\n","        #print(output.T, labels.type(torch.float32))\n","        loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        #accuracy = acc(output,labels)\n","        accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in val_dl:\n","            #print(inputs.shape)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            output = model(inputs)\n","            #print(\"output:\",output.squeeze())\n","            #print(\"labels:\",labels.long())\n","            val_loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","            val_acc += accuracy\n","            epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_dl.dataset)\n","    epoch_val_acc = val_acc/len(val_dl.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), f'model_{epoch}_loss_00001-{epoch_val_loss}_acc-{epoch_val_acc}')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"metadata":{"id":"BYiin2bmBccb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = go.Figure()\n","\n","# Add traces\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_loss,\n","                    mode='lines+markers',\n","                    name='loss'))\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_acc,\n","                    mode='lines+markers',\n","                    name='acc'))\n","fig.show()"],"metadata":{"id":"q5EZARpjBcWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3)\n","model.load_state_dict(torch.load('/kaggle/working/model_loss_00001-0.4798233907558872_acc-0.7717592402253012'))\n","model.to(device)\n","model.eval()\n","\n","corrects = 0\n","total = 0\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","all_pred_bin = np.empty((1,0))\n","all_labels = np.empty((1,0))\n","\n","for inputs, labels in test_dl:\n","    #print(inputs.shape)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred_test = predict_text(inputs)\n","    #print(torch.squeeze(pred_test, 1).type(torch.float32))\n","    all_pred_bin = np.append(all_pred_bin, (torch.squeeze(pred_test, 1).type(torch.float32) >= 0.5).type(torch.int).detach().cpu().numpy())\n","    all_labels = np.append(all_labels, labels.detach().cpu().numpy())\n","    #print(torch.squeeze(pred_test.T, 0), labels.type(torch.float32))\n","    corrects += acc(torch.squeeze(pred_test, 1).type(torch.float32), labels.type(torch.float32))#acc(pred_test, labels)\n","    #print(corrects)\n","    total += len(pred_test)\n","\n","print(precision_recall_fscore_support(all_labels, all_pred_bin, average='binary', pos_label=0))\n","print(confusion_matrix(all_labels, all_pred_bin))\n","print(classification_report(all_labels, all_pred_bin))\n","\n","print(corrects/total)\n","print(all_pred_bin.shape, all_pred_bin)\n","print(all_labels.shape, all_labels)\n","print(\"f1: \", f1_score(all_labels, all_pred_bin))\n","print(\"recall: \", recall_score(all_labels, all_pred_bin))\n","print(\"precision: \", precision_score(all_labels, all_pred_bin))\n","print(\"accuracy: \", accuracy_score(all_labels, all_pred_bin))"],"metadata":{"id":"dy7ycAarCWQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix(all_labels, all_pred_bin), display_labels=['racista','não racista'])\n","disp.plot(cmap='Blues')\n","plt.show()"],"metadata":{"id":"r6Fad-hkCWHq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset 3"],"metadata":{"id":"YmLHiIzw_aQR"}},{"cell_type":"code","source":["df_train = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb-3/big_dataset/big_train_dataset_3.feather')\n","df_val = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb-3/big_dataset/big_val_dataset_3.feather')\n","df_test = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb-3/big_dataset/big_test_dataset_3.feather')\n","\n","df_train = shuffle(df_train)\n","df_val = shuffle(df_val)\n","df_test = shuffle(df_test)\n","\n","train_y = df_train['label']\n","train_x = df_train['text']\n","\n","val_y = df_val['label']\n","val_x = df_val['text']\n","\n","test_y = df_test['label']\n","test_x = df_test['text']\n"],"metadata":{"id":"_-8dAHj2_bSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = train_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","val_x = val_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","test_x = test_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","\n","vocab_to_int = tweets_vocab(train_x)\n","train_x_tok, max_len1 = tweets_tok(train_x, vocab_to_int)\n","test_x_tok, _ = tweets_tok(test_x, vocab_to_int)\n","val_x_tok, _ = tweets_tok(val_x, vocab_to_int)\n","\n","max_len = 280\n","val_x_tok = padding(val_x_tok, max_len)\n","test_x_tok = padding(test_x_tok, max_len)\n","\n","num_words = 5000\n","\n","tokenizer = Tokenizer(num_words=num_words)\n","tokenizer.fit_on_texts(train_x)\n","\n","train_x_tokenized = tokenizer.texts_to_sequences(train_x)\n","test_x_tokenized = tokenizer.texts_to_sequences(test_x)\n","val_x_tokenized = tokenizer.texts_to_sequences(val_x)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","print(vocab_size)"],"metadata":{"id":"WXbXTUf5_pZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_padded = pad_sequences(train_x_tokenized, maxlen=max_length, padding='post')\n","test_x_padded = pad_sequences(test_x_tokenized, maxlen=max_length, padding='post')\n","val_x_padded = pad_sequences(val_x_tokenized, maxlen=max_length, padding='post')\n","\n","train_x_padded = np.array(train_x_padded)\n","val_x_padded = np.array(val_x_padded)\n","test_x_padded = np.array(test_x_padded)\n","\n","train_y = np.array(train_y)\n","val_y = np.array(val_y)\n","test_y = np.array(test_y)\n"],"metadata":{"id":"Qv69QqC__pVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = TensorDataset(torch.from_numpy(np.expand_dims(train_x_padded, axis=2)).type(torch.float32), torch.from_numpy(train_y))\n","#train_ds = torch.utils.data.ConcatDataset([train_1_ds, train_2_ds])\n","val_ds = TensorDataset(torch.from_numpy(np.expand_dims(val_x_padded, axis=2)).type(torch.float32), torch.from_numpy(val_y))\n","test_ds = TensorDataset(torch.from_numpy(np.expand_dims(test_x_padded, axis=2)).type(torch.float32), torch.from_numpy(test_y))\n","\n","batch_size = 256\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n","val_dl = DataLoader(val_ds, shuffle=True, batch_size=batch_size)\n","test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"XxjBpzluA_L0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3).to(device)\n","\n","weights = [len(train_y)/(2*(len(train_y)-train_y.sum())), len(train_y)/(2*train_y.sum())]\n","criterion = BCELoss_class_weighted(weights)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"],"metadata":{"id":"9h2J9-VWA_CE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clip = 5\n","epochs = 50\n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","print(len(train_dl.dataset))\n","print(len(val_dl.dataset))\n","\n","\n","\n","for epoch in range(epochs):\n","    print(\"epoch:\", epoch)\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    for inputs, labels in train_dl:\n","        #print(inputs.shape)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","      \n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        \n","        # calculate the loss and perform backprop\n","        #print(\"output:\",output.shape, output[0].shape, output[0].dtype)\n","        #print(\"labels:\",labels.shape, labels.dtype)\n","        #print(output, torch.max(labels,1)[1])\n","        #print(output.T, labels.type(torch.float32))\n","        loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        #accuracy = acc(output,labels)\n","        accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in val_dl:\n","            #print(inputs.shape)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            output = model(inputs)\n","            #print(\"output:\",output.squeeze())\n","            #print(\"labels:\",labels.long())\n","            val_loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","            val_acc += accuracy\n","            epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_dl.dataset)\n","    epoch_val_acc = val_acc/len(val_dl.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), f'model_{epoch}_loss_00001-{epoch_val_loss}_acc-{epoch_val_acc}')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"metadata":{"id":"45Q0ApIDBeE1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = go.Figure()\n","\n","# Add traces\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_loss,\n","                    mode='lines+markers',\n","                    name='loss'))\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_acc,\n","                    mode='lines+markers',\n","                    name='acc'))\n","fig.show()"],"metadata":{"id":"nZmW7rTEBd-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3)\n","model.load_state_dict(torch.load('/kaggle/working/model_loss_00001-0.4798233907558872_acc-0.7717592402253012'))\n","model.to(device)\n","model.eval()\n","\n","corrects = 0\n","total = 0\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","all_pred_bin = np.empty((1,0))\n","all_labels = np.empty((1,0))\n","\n","for inputs, labels in test_dl:\n","    #print(inputs.shape)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred_test = predict_text(inputs)\n","    #print(torch.squeeze(pred_test, 1).type(torch.float32))\n","    all_pred_bin = np.append(all_pred_bin, (torch.squeeze(pred_test, 1).type(torch.float32) >= 0.5).type(torch.int).detach().cpu().numpy())\n","    all_labels = np.append(all_labels, labels.detach().cpu().numpy())\n","    #print(torch.squeeze(pred_test.T, 0), labels.type(torch.float32))\n","    corrects += acc(torch.squeeze(pred_test, 1).type(torch.float32), labels.type(torch.float32))#acc(pred_test, labels)\n","    #print(corrects)\n","    total += len(pred_test)\n","\n","print(precision_recall_fscore_support(all_labels, all_pred_bin, average='binary', pos_label=0))\n","print(confusion_matrix(all_labels, all_pred_bin))\n","print(classification_report(all_labels, all_pred_bin))\n","\n","print(corrects/total)\n","print(all_pred_bin.shape, all_pred_bin)\n","print(all_labels.shape, all_labels)\n","print(\"f1: \", f1_score(all_labels, all_pred_bin))\n","print(\"recall: \", recall_score(all_labels, all_pred_bin))\n","print(\"precision: \", precision_score(all_labels, all_pred_bin))\n","print(\"accuracy: \", accuracy_score(all_labels, all_pred_bin))\n"],"metadata":{"id":"eJdvetXuCYZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix(all_labels, all_pred_bin), display_labels=['racista','não racista'])\n","disp.plot(cmap='Blues')\n","plt.show()"],"metadata":{"id":"6z2l3gmICYRk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset 4"],"metadata":{"id":"M_TSh-Pc_cAv"}},{"cell_type":"code","source":["df_train = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-4/big_train_dataset_4.feather')\n","df_val = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-4/big_val_dataset_4.feather')\n","df_test = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-4/big_test_dataset_4.feather')\n","\n","df_train = shuffle(df_train)\n","df_val = shuffle(df_val)\n","df_test = shuffle(df_test)\n","\n","train_y = df_train['label']\n","train_x = df_train['text']\n","\n","val_y = df_val['label']\n","val_x = df_val['text']\n","\n","test_y = df_test['label']\n","test_x = df_test['text']\n"],"metadata":{"id":"nw6ZZj3g_c-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = train_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","val_x = val_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","test_x = test_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","\n","vocab_to_int = tweets_vocab(train_x)\n","train_x_tok, max_len1 = tweets_tok(train_x, vocab_to_int)\n","test_x_tok, _ = tweets_tok(test_x, vocab_to_int)\n","val_x_tok, _ = tweets_tok(val_x, vocab_to_int)\n","\n","max_len = 280\n","val_x_tok = padding(val_x_tok, max_len)\n","test_x_tok = padding(test_x_tok, max_len)\n","\n","num_words = 5000\n","\n","tokenizer = Tokenizer(num_words=num_words)\n","tokenizer.fit_on_texts(train_x)\n","\n","train_x_tokenized = tokenizer.texts_to_sequences(train_x)\n","test_x_tokenized = tokenizer.texts_to_sequences(test_x)\n","val_x_tokenized = tokenizer.texts_to_sequences(val_x)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","print(vocab_size)"],"metadata":{"id":"jbpLWqlR_q_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_padded = pad_sequences(train_x_tokenized, maxlen=max_length, padding='post')\n","test_x_padded = pad_sequences(test_x_tokenized, maxlen=max_length, padding='post')\n","val_x_padded = pad_sequences(val_x_tokenized, maxlen=max_length, padding='post')\n","\n","train_x_padded = np.array(train_x_padded)\n","val_x_padded = np.array(val_x_padded)\n","test_x_padded = np.array(test_x_padded)\n","\n","train_y = np.array(train_y)\n","val_y = np.array(val_y)\n","test_y = np.array(test_y)\n"],"metadata":{"id":"-wEQWnig_q5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = TensorDataset(torch.from_numpy(np.expand_dims(train_x_padded, axis=2)).type(torch.float32), torch.from_numpy(train_y))\n","#train_ds = torch.utils.data.ConcatDataset([train_1_ds, train_2_ds])\n","val_ds = TensorDataset(torch.from_numpy(np.expand_dims(val_x_padded, axis=2)).type(torch.float32), torch.from_numpy(val_y))\n","test_ds = TensorDataset(torch.from_numpy(np.expand_dims(test_x_padded, axis=2)).type(torch.float32), torch.from_numpy(test_y))\n","\n","batch_size = 256\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n","val_dl = DataLoader(val_ds, shuffle=True, batch_size=batch_size)\n","test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"P1VX8VjOBBBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3).to(device)\n","\n","weights = [len(train_y)/(2*(len(train_y)-train_y.sum())), len(train_y)/(2*train_y.sum())]\n","criterion = BCELoss_class_weighted(weights)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"],"metadata":{"id":"EJPzBXZyBA4Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clip = 5\n","epochs = 50\n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","print(len(train_dl.dataset))\n","print(len(val_dl.dataset))\n","\n","\n","\n","for epoch in range(epochs):\n","    print(\"epoch:\", epoch)\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    for inputs, labels in train_dl:\n","        #print(inputs.shape)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","      \n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        \n","        # calculate the loss and perform backprop\n","        #print(\"output:\",output.shape, output[0].shape, output[0].dtype)\n","        #print(\"labels:\",labels.shape, labels.dtype)\n","        #print(output, torch.max(labels,1)[1])\n","        #print(output.T, labels.type(torch.float32))\n","        loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        #accuracy = acc(output,labels)\n","        accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in val_dl:\n","            #print(inputs.shape)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            output = model(inputs)\n","            #print(\"output:\",output.squeeze())\n","            #print(\"labels:\",labels.long())\n","            val_loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","            val_acc += accuracy\n","            epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_dl.dataset)\n","    epoch_val_acc = val_acc/len(val_dl.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), f'model_{epoch}_loss_00001-{epoch_val_loss}_acc-{epoch_val_acc}')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"metadata":{"id":"cn8e32gSBgOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = go.Figure()\n","\n","# Add traces\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_loss,\n","                    mode='lines+markers',\n","                    name='loss'))\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_acc,\n","                    mode='lines+markers',\n","                    name='acc'))\n","fig.show()"],"metadata":{"id":"2T4uER_zBgII"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3)\n","model.load_state_dict(torch.load('/kaggle/working/model_loss_00001-0.4798233907558872_acc-0.7717592402253012'))\n","model.to(device)\n","model.eval()\n","\n","corrects = 0\n","total = 0\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","all_pred_bin = np.empty((1,0))\n","all_labels = np.empty((1,0))\n","\n","for inputs, labels in test_dl:\n","    #print(inputs.shape)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred_test = predict_text(inputs)\n","    #print(torch.squeeze(pred_test, 1).type(torch.float32))\n","    all_pred_bin = np.append(all_pred_bin, (torch.squeeze(pred_test, 1).type(torch.float32) >= 0.5).type(torch.int).detach().cpu().numpy())\n","    all_labels = np.append(all_labels, labels.detach().cpu().numpy())\n","    #print(torch.squeeze(pred_test.T, 0), labels.type(torch.float32))\n","    corrects += acc(torch.squeeze(pred_test, 1).type(torch.float32), labels.type(torch.float32))#acc(pred_test, labels)\n","    #print(corrects)\n","    total += len(pred_test)\n","\n","print(precision_recall_fscore_support(all_labels, all_pred_bin, average='binary', pos_label=0))\n","print(confusion_matrix(all_labels, all_pred_bin))\n","print(classification_report(all_labels, all_pred_bin))\n","\n","print(corrects/total)\n","print(all_pred_bin.shape, all_pred_bin)\n","print(all_labels.shape, all_labels)\n","print(\"f1: \", f1_score(all_labels, all_pred_bin))\n","print(\"recall: \", recall_score(all_labels, all_pred_bin))\n","print(\"precision: \", precision_score(all_labels, all_pred_bin))\n","print(\"accuracy: \", accuracy_score(all_labels, all_pred_bin))"],"metadata":{"id":"MIqPBT-lCaWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix(all_labels, all_pred_bin), display_labels=['racista','não racista'])\n","disp.plot(cmap='Blues')\n","plt.show()"],"metadata":{"id":"7uS1RItUCadp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset 5"],"metadata":{"id":"EUDD-kAN_di7"}},{"cell_type":"code","source":["df_train = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-5/big_train_dataset_5.feather')\n","df_val = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-5/big_val_dataset_5.feather')\n","df_test = pd.read_feather('/content/drive/MyDrive/poli-tcc/lstm_cnn_emb/big_dataset-5/big_test_dataset_5.feather')\n","\n","df_train = shuffle(df_train)\n","df_val = shuffle(df_val)\n","df_test = shuffle(df_test)\n","\n","train_y = df_train['label']\n","train_x = df_train['text']\n","\n","val_y = df_val['label']\n","val_x = df_val['text']\n","\n","test_y = df_test['label']\n","test_x = df_test['text']\n"],"metadata":{"id":"Ms3y1hxT_exb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = train_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","val_x = val_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","test_x = test_x.apply(lambda x:separateEmoji(x)).apply(lambda x:removeMention(x)).apply(lambda x:removeLink(x)).apply(lambda x:splitPunctuation(x)).apply(lambda x: x.lower()).apply(lambda x:remove_stopwords(x))\n","\n","vocab_to_int = tweets_vocab(train_x)\n","train_x_tok, max_len1 = tweets_tok(train_x, vocab_to_int)\n","test_x_tok, _ = tweets_tok(test_x, vocab_to_int)\n","val_x_tok, _ = tweets_tok(val_x, vocab_to_int)\n","\n","max_len = 280\n","val_x_tok = padding(val_x_tok, max_len)\n","test_x_tok = padding(test_x_tok, max_len)\n","\n","num_words = 5000\n","\n","tokenizer = Tokenizer(num_words=num_words)\n","tokenizer.fit_on_texts(train_x)\n","\n","train_x_tokenized = tokenizer.texts_to_sequences(train_x)\n","test_x_tokenized = tokenizer.texts_to_sequences(test_x)\n","val_x_tokenized = tokenizer.texts_to_sequences(val_x)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","print(vocab_size)"],"metadata":{"id":"IyklqIbE_sg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_padded = pad_sequences(train_x_tokenized, maxlen=max_length, padding='post')\n","test_x_padded = pad_sequences(test_x_tokenized, maxlen=max_length, padding='post')\n","val_x_padded = pad_sequences(val_x_tokenized, maxlen=max_length, padding='post')\n","\n","train_x_padded = np.array(train_x_padded)\n","val_x_padded = np.array(val_x_padded)\n","test_x_padded = np.array(test_x_padded)\n","\n","train_y = np.array(train_y)\n","val_y = np.array(val_y)\n","test_y = np.array(test_y)\n"],"metadata":{"id":"SRMMc2cZ_sao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = TensorDataset(torch.from_numpy(np.expand_dims(train_x_padded, axis=2)).type(torch.float32), torch.from_numpy(train_y))\n","#train_ds = torch.utils.data.ConcatDataset([train_1_ds, train_2_ds])\n","val_ds = TensorDataset(torch.from_numpy(np.expand_dims(val_x_padded, axis=2)).type(torch.float32), torch.from_numpy(val_y))\n","test_ds = TensorDataset(torch.from_numpy(np.expand_dims(test_x_padded, axis=2)).type(torch.float32), torch.from_numpy(test_y))\n","\n","batch_size = 256\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n","val_dl = DataLoader(val_ds, shuffle=True, batch_size=batch_size)\n","test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"XgOAPPJBBCBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3).to(device)\n","\n","weights = [len(train_y)/(2*(len(train_y)-train_y.sum())), len(train_y)/(2*train_y.sum())]\n","criterion = BCELoss_class_weighted(weights)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"],"metadata":{"id":"Ev2Bm4cEBB6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clip = 5\n","epochs = 50\n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","print(len(train_dl.dataset))\n","print(len(val_dl.dataset))\n","\n","\n","\n","for epoch in range(epochs):\n","    print(\"epoch:\", epoch)\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    for inputs, labels in train_dl:\n","        #print(inputs.shape)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","      \n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        \n","        # calculate the loss and perform backprop\n","        #print(\"output:\",output.shape, output[0].shape, output[0].dtype)\n","        #print(\"labels:\",labels.shape, labels.dtype)\n","        #print(output, torch.max(labels,1)[1])\n","        #print(output.T, labels.type(torch.float32))\n","        loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        #accuracy = acc(output,labels)\n","        accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in val_dl:\n","            #print(inputs.shape)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            output = model(inputs)\n","            #print(\"output:\",output.squeeze())\n","            #print(\"labels:\",labels.long())\n","            val_loss = criterion(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(torch.squeeze(output, 1).type(torch.float32), labels.type(torch.float32))\n","            val_acc += accuracy\n","            epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_dl.dataset)\n","    epoch_val_acc = val_acc/len(val_dl.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), f'model_{epoch}_loss_00001-{epoch_val_loss}_acc-{epoch_val_acc}')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"metadata":{"id":"iDftH5EpBh7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = go.Figure()\n","\n","# Add traces\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_loss,\n","                    mode='lines+markers',\n","                    name='loss'))\n","fig.add_trace(go.Scatter(x=[i for i in range(50)], y=epoch_vl_acc,\n","                    mode='lines+markers',\n","                    name='acc'))\n","fig.show()"],"metadata":{"id":"jEvcI7N2Bh1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TweetsLSTM(no_layers,hidden_dim,input_dim,drop_prob=0.3)\n","model.load_state_dict(torch.load('/kaggle/working/model_loss_00001-0.4798233907558872_acc-0.7717592402253012'))\n","model.to(device)\n","model.eval()\n","\n","corrects = 0\n","total = 0\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","all_pred_bin = np.empty((1,0))\n","all_labels = np.empty((1,0))\n","\n","for inputs, labels in test_dl:\n","    #print(inputs.shape)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred_test = predict_text(inputs)\n","    #print(torch.squeeze(pred_test, 1).type(torch.float32))\n","    all_pred_bin = np.append(all_pred_bin, (torch.squeeze(pred_test, 1).type(torch.float32) >= 0.5).type(torch.int).detach().cpu().numpy())\n","    all_labels = np.append(all_labels, labels.detach().cpu().numpy())\n","    #print(torch.squeeze(pred_test.T, 0), labels.type(torch.float32))\n","    corrects += acc(torch.squeeze(pred_test, 1).type(torch.float32), labels.type(torch.float32))#acc(pred_test, labels)\n","    #print(corrects)\n","    total += len(pred_test)\n","\n","print(precision_recall_fscore_support(all_labels, all_pred_bin, average='binary', pos_label=0))\n","print(confusion_matrix(all_labels, all_pred_bin))\n","print(classification_report(all_labels, all_pred_bin))\n","\n","print(corrects/total)\n","print(all_pred_bin.shape, all_pred_bin)\n","print(all_labels.shape, all_labels)\n","print(\"f1: \", f1_score(all_labels, all_pred_bin))\n","print(\"recall: \", recall_score(all_labels, all_pred_bin))\n","print(\"precision: \", precision_score(all_labels, all_pred_bin))\n","print(\"accuracy: \", accuracy_score(all_labels, all_pred_bin))\n"],"metadata":{"id":"dncLXjJyCcrp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix(all_labels, all_pred_bin), display_labels=['racista','não racista'])\n","disp.plot(cmap='Blues')\n","plt.show()"],"metadata":{"id":"X1WAL9H_CcmG"},"execution_count":null,"outputs":[]}]}